{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS Loader\n",
    "\n",
    "\n",
    "We use the data in `SpineGeneric`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bids_neuropoly import bids\n",
    "from medicaltorch import datasets as mt_datasets\n",
    "from medicaltorch import transforms as mt_transforms\n",
    "from medicaltorch import filters as mt_filters\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class SliceFilter(mt_filters.SliceFilter):\n",
    "    \"\"\"This class extends the SliceFilter that already\n",
    "    filters for empty labels and inputs. It will filter\n",
    "    slices that has only zeros after cropping. To avoid\n",
    "    feeding empty inputs into the network.\n",
    "    \"\"\"\n",
    "    def __call__(self, sample):\n",
    "        super_ret = super().__call__(sample)\n",
    "\n",
    "        # Already filtered by base class\n",
    "        if not super_ret:\n",
    "            return super_ret\n",
    "\n",
    "        # Filter slices where there are no values after cropping\n",
    "        input_img = Image.fromarray(sample['input'], mode='F')\n",
    "        input_cropped = transforms.functional.center_crop(input_img, (128, 128))\n",
    "        input_cropped = np.array(input_cropped)\n",
    "        count = np.count_nonzero(input_cropped)\n",
    "\n",
    "        if count <= 0:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "    \n",
    "class BIDSSegPair2D(mt_datasets.SegmentationPair2D):\n",
    "    def __init__(self, input_filename, gt_filename, metadata):\n",
    "        super().__init__(input_filename, gt_filename)\n",
    "        self.metadata = metadata\n",
    "        self.metadata[\"input_filename\"] = input_filename\n",
    "        self.metadata[\"gt_filename\"] = gt_filename\n",
    "\n",
    "    def get_pair_slice(self, slice_index, slice_axis=2):\n",
    "        dreturn = super().get_pair_slice(slice_index, slice_axis)\n",
    "        self.metadata[\"slice_index\"] = slice_index\n",
    "        dreturn[\"input_metadata\"][\"bids_metadata\"] = self.metadata\n",
    "        return dreturn\n",
    "\n",
    "\n",
    "class MRI2DBidsSegDataset(mt_datasets.MRI2DSegmentationDataset):\n",
    "    def _load_filenames(self):\n",
    "        for input_filename, gt_filename, bids_metadata in self.filename_pairs:\n",
    "            segpair = BIDSSegPair2D(input_filename, gt_filename,\n",
    "                                    bids_metadata)\n",
    "            self.handlers.append(segpair)\n",
    "\n",
    "\n",
    "class BidsDataset(MRI2DBidsSegDataset):\n",
    "    def __init__(self, root_dir, slice_axis=2, cache=True,\n",
    "                 transform=None, slice_filter_fn=None,\n",
    "                 canonical=False, labeled=True):\n",
    "        self.bids_ds = bids.BIDS(root_dir)\n",
    "        self.filename_pairs = []\n",
    "        self.metadata = {\"FlipAngle\": [], \"RepetitionTime\": [], \"EchoTime\": [], \"Manufacturer\": []}\n",
    "\n",
    "        for subject in self.bids_ds.get_subjects():\n",
    "\n",
    "            if not subject.has_derivative(\"labels\"):\n",
    "                print(\"Subject without derivative, skipping.\")\n",
    "                continue\n",
    "            derivatives = subject.get_derivatives(\"labels\")\n",
    "            cord_label_filename = None\n",
    "\n",
    "            for deriv in derivatives:\n",
    "                if deriv.endswith(\"seg-manual.nii.gz\"):\n",
    "                    cord_label_filename = deriv\n",
    "\n",
    "            if cord_label_filename is None:\n",
    "                continue\n",
    "\n",
    "            if not subject.has_metadata():\n",
    "                print(\"Subject without metadata.\")\n",
    "                continue\n",
    "\n",
    "            metadata = subject.metadata()\n",
    "            \n",
    "\n",
    "            self.filename_pairs.append((subject.record.absolute_path,\n",
    "                                        cord_label_filename, metadata))\n",
    "\n",
    "        super().__init__(self.filename_pairs, slice_axis, cache,\n",
    "                         transform, slice_filter_fn, canonical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Here we define the architecture of the network in a PyTorch Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DownConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, drop_rate=0.2, bn_momentum=0.1):\n",
    "        super(DownConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_ch, out_channels=out_ch, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_bn = nn.BatchNorm2d(out_ch, momentum=bn_momentum)\n",
    "        self.conv_drop = nn.Dropout2d(drop_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x))\n",
    "        x = self.conv_bn(x)\n",
    "        x = self.conv_drop(x)\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, drop_rate=0.2, bn_momentum=0.1):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv1 = DownConv(1, 32, drop_rate, bn_momentum)\n",
    "        self.mp1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv2 = DownConv(32, 32, drop_rate, bn_momentum)\n",
    "        self.mp2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv3 = DownConv(32, 64, drop_rate, bn_momentum)\n",
    "        self.mp3 = nn.MaxPool2d(2)       \n",
    "        \n",
    "        self.flat = Flatten()\n",
    "        self.dense1 = nn.Linear(16384, 512)\n",
    "        self.drop = nn.Dropout2d(drop_rate)\n",
    "        self.dense2 = nn.Linear(512, 6)\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.mp1(x1)\n",
    "        \n",
    "        x3 = self.conv2(x2)\n",
    "        x4 = self.mp2(x3)\n",
    "        \n",
    "        x5 = self.conv3(x4)\n",
    "        x6 = self.mp3(x5)\n",
    "        \n",
    "        x7 = self.flat(x6)\n",
    "        x8 = F.relu(self.dense1(x7))\n",
    "        x9 = self.drop(x8)\n",
    "        x10 = self.dense2(x9)\n",
    "        x11 = self.soft(x10)\n",
    "\n",
    "        return(x11)\n",
    "\n",
    "#torch tensors are of the format (batch_size, n_channels, shape_of_image)\n",
    "a = torch.rand(18,1,128,128)\n",
    "test = Classifier().forward(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import time\n",
    "import shutil\n",
    "import sys\n",
    "import pickle\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def get_modality_path(path):\n",
    "    if \"acq-MToff_MTS\" in path :\n",
    "        return 0\n",
    "    if \"acq-MTon_MTS\" in path :\n",
    "        return 1\n",
    "    if \"acq-T1w_MTS\" in path :\n",
    "        return 2\n",
    "    if \"T1w\" in path :\n",
    "        return 3\n",
    "    if \"T2star\" in path :\n",
    "        return 4\n",
    "    if \"T2w\" in path :\n",
    "        return 5\n",
    "    raise RuntimeError(f\"Incorrect path for {path}.\")\n",
    "\n",
    "def get_modality_batch(batch, path=None):\n",
    "    labels = []\n",
    " \n",
    "    for acq in batch['input_metadata']:\n",
    "        path = acq.__getitem__('bids_metadata')['input_filename']\n",
    "        labels.append(get_modality_path(path))\n",
    "        \n",
    "    return labels\n",
    "\n",
    "def OneHotEncode(labels):\n",
    "    ohe_labels = []\n",
    "    for label in labels :\n",
    "        ohe = [0 for i in range(6)]\n",
    "        ohe[label] = 1 \n",
    "        ohe_labels.append(ohe)\n",
    "    return torch.cuda.FloatTensor(ohe_labels)\n",
    "\n",
    "\n",
    "def cmd_train(context):\n",
    "    \"\"\"Main command do train the network.\n",
    "    :param context: this is a dictionary with all data from the\n",
    "                    configuration file:\n",
    "                        - 'command': run the specified command (e.g. train, test)\n",
    "                        - 'gpu': ID of the used GPU\n",
    "                        - 'bids_path_train': list of relative paths of the BIDS folders of each training center\n",
    "                        - 'bids_path_validation': list of relative paths of the BIDS folders of each validation center\n",
    "                        - 'bids_path_test': list of relative paths of the BIDS folders of each test center\n",
    "                        - 'batch_size'\n",
    "                        - 'dropout_rate'\n",
    "                        - 'batch_norm_momentum'\n",
    "                        - 'num_epochs'\n",
    "                        - 'initial_lr': initial learning rate\n",
    "                        - 'log_directory': folder name where log files are saved\n",
    "                        - 'debugging': allows extended verbosity and intermediate outputs\n",
    "    \"\"\"\n",
    "    # Set the GPU\n",
    "    gpu_number = int(0)\n",
    "    torch.cuda.set_device(gpu_number)\n",
    "\n",
    "    # These are the training transformations\n",
    "    train_transform = transforms.Compose([\n",
    "        mt_transforms.CenterCrop2D((128, 128)),\n",
    "        mt_transforms.ElasticTransform(alpha_range=(28.0, 30.0),\n",
    "                                       sigma_range=(3.5, 4.0),\n",
    "                                       p=0.3),\n",
    "        mt_transforms.RandomAffine(degrees=4.6,\n",
    "                                   scale=(0.98, 1.02),\n",
    "                                   translate=(0.03, 0.03)),\n",
    "        mt_transforms.RandomTensorChannelShift((-0.10, 0.10)),\n",
    "        mt_transforms.ToTensor(),\n",
    "        mt_transforms.NormalizeInstance(),\n",
    "    ])\n",
    "\n",
    "    # These are the validation/testing transformations\n",
    "    val_transform = transforms.Compose([\n",
    "        mt_transforms.CenterCrop2D((128, 128)),\n",
    "        mt_transforms.ToTensor(),\n",
    "        mt_transforms.NormalizeInstance(),\n",
    "    ])\n",
    "\n",
    "    # This code will iterate over the folders and load the data, filtering\n",
    "    # the slices without labels and then concatenating all the datasets together\n",
    "    train_datasets = []\n",
    "    for bids_ds in tqdm_notebook(context[\"bids_path_train\"], desc=\"Loading training set\"):\n",
    "        ds_train = BidsDataset(bids_ds,\n",
    "                               transform=train_transform,\n",
    "                               slice_filter_fn=SliceFilter())\n",
    "        train_datasets.append(ds_train)\n",
    "\n",
    "    ds_train = ConcatDataset(train_datasets)\n",
    "    print(f\"Loaded {len(ds_train)} axial slices for the training set.\")\n",
    "    train_loader = DataLoader(ds_train, batch_size=context[\"batch_size\"],\n",
    "                              shuffle=True, pin_memory=True,\n",
    "                              collate_fn=mt_datasets.mt_collate,\n",
    "                              num_workers=1)\n",
    "    \n",
    "    # Validation dataset ------------------------------------------------------\n",
    "    validation_datasets = []\n",
    "    for bids_ds in tqdm_notebook(context[\"bids_path_validation\"], desc=\"Loading validation set\"):\n",
    "        ds_val = BidsDataset(bids_ds,\n",
    "                             transform=val_transform,\n",
    "                             slice_filter_fn=SliceFilter())\n",
    "        validation_datasets.append(ds_val)\n",
    "\n",
    "    ds_val = ConcatDataset(validation_datasets)\n",
    "    print(f\"Loaded {len(ds_val)} axial slices for the validation set.\")\n",
    "    val_loader = DataLoader(ds_val, batch_size=context[\"batch_size\"],\n",
    "                            shuffle=True, pin_memory=True,\n",
    "                            collate_fn=mt_datasets.mt_collate,\n",
    "                            num_workers=0)\n",
    "    \n",
    "    \n",
    "    # Model definition ---------------------------------------------------------\n",
    "    model = Classifier(drop_rate=context[\"dropout_rate\"],\n",
    "                       bn_momentum=context[\"batch_norm_momentum\"])\n",
    "\n",
    "    model.cuda()\n",
    "\n",
    "    num_epochs = context[\"num_epochs\"]\n",
    "    initial_lr = context[\"initial_lr\"]\n",
    "\n",
    "    # Using SGD with cosine annealing learning rate\n",
    "    optimizer = optim.SGD(model.parameters(), lr=initial_lr)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)\n",
    "\n",
    "    # Write the metrics, images, etc to TensorBoard format\n",
    "    writer = SummaryWriter(logdir=context[\"log_directory\"])\n",
    "    \n",
    "    # Binary Cross Entropy Loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    \n",
    "    # Training loop -----------------------------------------------------------\n",
    "    best_validation_loss = float(\"inf\")\n",
    "    \n",
    "    lst_train_loss = []\n",
    "    lst_val_loss = []\n",
    "    lst_accuracy = []\n",
    "    \n",
    "    for epoch in tqdm_notebook(range(1, num_epochs+1), desc=\"Training\"):\n",
    "        start_time = time.time()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        lr = scheduler.get_lr()[0]\n",
    "        writer.add_scalar('learning_rate', lr, epoch)\n",
    "\n",
    "        model.train()\n",
    "        train_loss_total = 0.0\n",
    "        num_steps = 0\n",
    "    \n",
    "        for i, batch in enumerate(train_loader):\n",
    "            input_samples = batch[\"input\"]\n",
    "            input_labels = get_modality_batch(batch)\n",
    "            \n",
    "            var_input = input_samples.cuda()\n",
    "            var_labels = torch.cuda.LongTensor(input_labels).cuda(non_blocking=True)\n",
    "\n",
    "            outputs = model(var_input)\n",
    "            \n",
    "            loss = criterion(outputs, var_labels)\n",
    "            train_loss_total += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            num_steps += 1\n",
    "            \n",
    "        train_loss_total_avg = train_loss_total / num_steps\n",
    "        lst_train_loss.append(train_loss_total_avg)\n",
    "        \n",
    "        #tqdm.write(f\"Epoch {epoch} training loss: {train_loss_total_avg:.4f}.\")\n",
    "        print(f\"Epoch {epoch} training loss: {train_loss_total_avg:.4f}.\")\n",
    "        \n",
    "        \n",
    "        # Validation loop -----------------------------------------------------\n",
    "        model.eval()\n",
    "        val_loss_total = 0.0\n",
    "        num_steps = 0\n",
    "        \n",
    "        val_accuracy = 0\n",
    "        num_samples = 0\n",
    "    \n",
    "        \n",
    "        for i, batch in enumerate(val_loader):\n",
    "            input_samples = batch[\"input\"]\n",
    "            input_labels = get_modality_batch(batch)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                var_input = input_samples.cuda()\n",
    "                var_labels = torch.cuda.LongTensor(input_labels).cuda(non_blocking=True)\n",
    "\n",
    "                outputs = model(var_input)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                loss = criterion(outputs, var_labels)\n",
    "                val_loss_total += loss.item()\n",
    "                \n",
    "                val_accuracy += int((var_labels == preds).sum())\n",
    "                \n",
    "            num_steps += 1\n",
    "            num_samples += context['batch_size']\n",
    "            \n",
    "        val_loss_total_avg = val_loss_total / num_steps\n",
    "        lst_val_loss.append(val_loss_total_avg)\n",
    "        \n",
    "        #tqdm.write(f\"Epoch {epoch} validation loss: {val_loss_total_avg:.4f}.\")\n",
    "        print(f\"Epoch {epoch} validation loss: {val_loss_total_avg:.4f}.\")\n",
    "        \n",
    "        val_accuracy_avg = 100 * val_accuracy / num_samples\n",
    "        lst_accuracy.append(val_accuracy_avg)\n",
    "        \n",
    "        #tqdm.write(f\"Epoch {epoch} accuracy : {val_accuracy_avg:.4f}.\")\n",
    "        print(f\"Epoch {epoch} accuracy : {val_accuracy_avg:.4f} %.\")\n",
    "        \n",
    "        #add metrics for tensorboard\n",
    "        writer.add_scalars('validation metrics', {\n",
    "            'accuracy' :accuracy,\n",
    "        }, epoch)\n",
    "        \n",
    "        writer.add_scalars('losses', {\n",
    "            'train_loss': train_loss_total_avg,\n",
    "            'val_loss': val_loss_total_avg,\n",
    "        }, epoch)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        #tqdm.write(\"Epoch {} took {:.2f} seconds.\".format(epoch, total_time))\n",
    "        print(\"Epoch {} took {:.2f} seconds.\".format(epoch, total_time))\n",
    "        \n",
    "        \n",
    "        \n",
    "        if val_loss_total_avg < best_validation_loss:\n",
    "            best_validation_loss = val_loss_total_avg\n",
    "            torch.save(model.state_dict(), \"./\"+context[\"log_directory\"]+\"/best_model.pt\")\n",
    "\n",
    "        \n",
    "    # save final model\n",
    "    torch.save(model.state_dict(), \"./\"+context[\"log_directory\"]+\"/final_model.pt\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def run_main(command):\n",
    "    with open('config/config.json') as fhandle:\n",
    "        context = json.load(fhandle)\n",
    "\n",
    "    #command = context[\"command\"]\n",
    "\n",
    "    if command == 'train':\n",
    "        cmd_train(context)\n",
    "        #shutil.copyfile(sys.argv[1], \"./\"+context[\"log_directory\"]+\"/config_file.json\")\n",
    "    elif command == 'test':\n",
    "        cmd_test(context)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847c9c8e0965446880fc79acb39feb64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading training set', max=6, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3518 axial slices for the training set.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7500d87676b34b628ffe4ed22daef69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading validation set', max=4, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-224-605e57d8d36f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-223-acece3a851b5>\u001b[0m in \u001b[0;36mrun_main\u001b[0;34m(command)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mcmd_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0;31m#shutil.copyfile(sys.argv[1], \"./\"+context[\"log_directory\"]+\"/config_file.json\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-223-acece3a851b5>\u001b[0m in \u001b[0;36mcmd_train\u001b[0;34m(context)\u001b[0m\n\u001b[1;32m    122\u001b[0m         ds_val = BidsDataset(bids_ds,\n\u001b[1;32m    123\u001b[0m                              \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                              slice_filter_fn=SliceFilter())\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mvalidation_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-97debbe02628>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root_dir, slice_axis, cache, transform, slice_filter_fn, canonical, labeled)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         super().__init__(self.filename_pairs, slice_axis, cache,\n\u001b[0;32m---> 89\u001b[0;31m                          transform, slice_filter_fn, canonical)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/medicaltorch/datasets.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename_pairs, slice_axis, cache, transform, slice_filter_fn, canonical)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_filenames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_filenames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/medicaltorch/datasets.py\u001b[0m in \u001b[0;36m_prepare_indexes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_filter_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                     slice_pair = segpair.get_pair_slice(segpair_slice,\n\u001b[0;32m--> 230\u001b[0;31m                                                         self.slice_axis)\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mfilter_fn_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_filter_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-97debbe02628>\u001b[0m in \u001b[0;36mget_pair_slice\u001b[0;34m(self, slice_index, slice_axis)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_pair_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mdreturn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pair_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"slice_index\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mdreturn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_metadata\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bids_metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/medicaltorch/datasets.py\u001b[0m in \u001b[0;36mget_pair_slice\u001b[0;34m(self, slice_index, slice_axis)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0minput_dataobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_dataobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pair_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;31m# use dataobj to avoid caching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/medicaltorch/datasets.py\u001b[0m in \u001b[0;36mget_pair_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m         numpy array.\"\"\"\n\u001b[1;32m    117\u001b[0m         \u001b[0mcache_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'fill'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'unchanged'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# Handle unlabeled data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/nibabel/dataobj_images.py\u001b[0m in \u001b[0;36mget_fdata\u001b[0;34m(self, caching, dtype)\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fdata_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fdata_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcaching\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fill'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fdata_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m     \"\"\"\n\u001b[0;32m--> 591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/nibabel/arrayproxy.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;31m# Read array and scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unscaled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_read_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/nibabel/arrayproxy.py\u001b[0m in \u001b[0;36mget_unscaled\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    349\u001b[0m                                        \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                                        \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                                        mmap=self._mmap)\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/nibabel/volumeutils.py\u001b[0m in \u001b[0;36marray_from_file\u001b[0;34m(shape, in_dtype, infile, offset, order, mmap)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'readinto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mdata_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mn_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0mneeds_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    483\u001b[0m                                \"end-of-stream marker was reached\")\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_read_data\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0muncompress\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muncompress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0muncompress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36m_add_read_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_read_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_crc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrc32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_crc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_eof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_main('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' \n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def plot_metrics(metrics, acc, classes,\n",
    "                title=\"Validation metrics\",\n",
    "                cmap=None):\n",
    "    \n",
    "    colors = [(1,1,1), (1,1,1), (1,1,1)]\n",
    "    cm = LinearSegmentedColormap.from_list(\"white\",colors,N=1)\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    im = ax.imshow(metrics, interpolation=None, cmap=cm)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(metrics.shape[1]),\n",
    "           yticks=np.arange(metrics.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=[\"Recall\", \"Precision\"],\n",
    "           title=\"Accuracy over slices = \"+str(int(10000*acc)/100)+\"%\"\n",
    ")\n",
    "\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f'\n",
    "    for i in range(metrics.shape[0]):\n",
    "        for j in range(metrics.shape[1]):\n",
    "            ax.text(j, i, format(metrics[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"black\")\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a slice by slice accuracy measurement on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmd_test(context):\n",
    "\n",
    "    # Set the GPU\n",
    "    gpu_number = int(0)\n",
    "    torch.cuda.set_device(gpu_number)\n",
    "\n",
    "    # These are the validation/testing transformations\n",
    "    val_transform = transforms.Compose([\n",
    "        mt_transforms.CenterCrop2D((128, 128)),\n",
    "        mt_transforms.ToTensor(),\n",
    "        mt_transforms.NormalizeInstance(),\n",
    "    ])\n",
    "\n",
    "    test_datasets = []\n",
    "    for bids_ds in tqdm_notebook(context[\"bids_path_test\"], desc=\"Loading test set\"):\n",
    "        ds_test = BidsDataset(bids_ds,\n",
    "                                     transform=val_transform,\n",
    "                                     slice_filter_fn=SliceFilter())\n",
    "        test_datasets.append(ds_test)\n",
    "\n",
    "\n",
    "    ds_test = ConcatDataset(test_datasets)\n",
    "    print(f\"Loaded {len(ds_test)} axial slices for the test set.\")\n",
    "    test_loader = DataLoader(ds_test, batch_size=context[\"batch_size\"],\n",
    "                             shuffle=True, pin_memory=True,\n",
    "                             collate_fn=mt_datasets.mt_collate,\n",
    "                             num_workers=1)\n",
    "\n",
    "    model = Classifier()\n",
    "    model.load_state_dict(torch.load(\"./\"+context[\"log_directory\"]+\"/best_model.pt\", map_location=\"cuda:0\"))\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    #setting the lists for confusion matrix\n",
    "    true_labels = []\n",
    "    guessed_labels = []\n",
    "\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        input_samples = batch[\"input\"]\n",
    "        input_labels = get_modality_batch(batch)\n",
    "        \n",
    "        true_labels += input_labels\n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_input = input_samples.cuda()\n",
    "            test_labels = torch.cuda.LongTensor(input_labels).cuda(non_blocking=True)\n",
    "            \n",
    "            array = np.array(input_samples)\n",
    "            for i in range(np.shape(array)[0]):\n",
    "                sl = array[i][0]\n",
    "            \n",
    "            outputs = model(test_input)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            lst_labels = [int(x) for x in preds]\n",
    "            guessed_labels += lst_labels\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, guessed_labels)\n",
    "    recall = recall_score(true_labels, guessed_labels, average=None)\n",
    "    precision = precision_score(true_labels, guessed_labels, average=None)\n",
    "    \n",
    "    np.set_printoptions(precision=2)\n",
    "    \n",
    "    if not(os.path.exists(\"./temp/\")):\n",
    "        os.makedirs(\"./temp/\")\n",
    "        \n",
    "    class_names = [\"MToff_MTS\", \"MTon_MTS\", \"T1w_MTS\", \"T1w\", \"T2star\", \"T2w\"]\n",
    "    # Plot normalized confusion matrix\n",
    "    plot_confusion_matrix(true_labels, guessed_labels, classes=class_names, normalize=True,\n",
    "                          title='Normalized confusion matrix')\n",
    "    plt.savefig(\"./temp/test_cm.png\")\n",
    "    plot_metrics(np.array([recall, precision]), accuracy, class_names)\n",
    "    plt.savefig(\"./temp/test_accuracy.png\")\n",
    "    \n",
    "    print(f\"Accuracy over test slices : {accuracy}\")\n",
    "    print(f\"Recall over test slices : {recall}\")\n",
    "    print(f\"Precision over test slices : {precision}\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90871446736d468f9a594d67101bddd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading test set', max=4, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2036 axial slices for the test set.\n",
      "Accuracy over test slices : 0.9508840864440079\n",
      "Recall over test slices : [0.98 0.92 0.95 0.87 1.   1.  ]\n",
      "Precision over test slices : [0.95 0.94 0.89 0.95 1.   0.99]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_main(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we want to add another tool to visualize accuracy for whole acquisitions and make sure that accuracy remains high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from statistics import mode\n",
    "import torchvision.transforms.functional as Func\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "#from PIL import ImageStat\n",
    "\n",
    "\n",
    "\n",
    "class Acquisition():\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        \"\"\"\n",
    "        This method loads the slices in the slices attribute from the path.\n",
    "        At this point it is only a list of arrays and will only be converted\n",
    "        to tensor after transformations.\n",
    "        \"\"\"\n",
    "        nii_original = nib.load(path).get_data()\n",
    "        if nii_original.size == 0 :\n",
    "            raise RuntimeError(f\"Empty slice in subject {path}.\")\n",
    "        axial_slices = []\n",
    "        for i in range(nii_original.shape[2]):\n",
    "            axial_slices.append(nii_original[:,:,i])\n",
    "        self.slices = axial_slices\n",
    "        \n",
    "    def StandardizeTransform(self):\n",
    "        \"\"\"\n",
    "        This method standardizes each slices individually\n",
    "        \"\"\"\n",
    "        for i in range(len(self.slices)):\n",
    "            mean, std = self.slices[i].mean(), self.slices[i].std() \n",
    "            self.slices[i] = (self.slices[i] - mean) / std\n",
    "    \n",
    "    def CenterCropTransform(self, size=128):\n",
    "        \"\"\"\n",
    "        This method centers the image around the center\n",
    "        \"\"\"\n",
    "        for i in range(len(self.slices)):\n",
    "            y, x = self.slices[i].shape\n",
    "            \n",
    "            startx = x // 2 - (size // 2)\n",
    "            starty = y // 2 - (size // 2)\n",
    "            \n",
    "            if startx < 0 or starty < 0:\n",
    "                raise RuntimeError(\"Negative crop.\")\n",
    "            \n",
    "            self.slices[i] = self.slices[i][starty:starty + size,\n",
    "                                           startx:startx + size]\n",
    "    \n",
    "    def ToTensor(self):\n",
    "        \"\"\"\n",
    "        This method returns the tensor in the correct shape to feed the network\n",
    "        ie. torch.Size([16, 1, 128, 128]) with dtype = float\n",
    "        \"\"\"        \n",
    "        slices = np.asarray(self.slices, dtype=np.float32)\n",
    "        slices = np.expand_dims(slices, axis=1)\n",
    "        tensor = torch.FloatTensor(slices)\n",
    "        return(tensor)\n",
    "\n",
    "\n",
    "def classify_acquisition(input_path, model=None):\n",
    "       \n",
    "    slices = Acquisition(input_path)\n",
    "    slices.CenterCropTransform()\n",
    "    slices.StandardizeTransform()\n",
    "    input_slices = slices.ToTensor()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        input_slices = input_slices.cuda()\n",
    "\n",
    "        outputs = model(input_slices)   \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        preds = preds.tolist()\n",
    "        \n",
    "    numeral=[[preds.count(nb), nb] for nb in preds]\n",
    "    numeral.sort(key=lambda x:x[0], reverse=True)\n",
    "    modality = numeral[0][1]\n",
    "    return(modality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e16bc969c14d9a9abc31b1f7cc1460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading test set', max=4, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edcac9c8ec2b42498f830c983d52deaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=134), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_model(context):\n",
    "    \n",
    "    model = Classifier()\n",
    "    model.load_state_dict(torch.load(\"./log_baseline/best_model.pt\", map_location=\"cuda:0\"))\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    paths_subjects = []\n",
    "    paths_acq = []\n",
    "    paths_centers = context[\"bids_path_test\"] + context[\"bids_path_validation\"]\n",
    "    labels = []\n",
    "    preds = []\n",
    "    \n",
    "\n",
    "    for path_center in tqdm_notebook(paths_centers,\n",
    "                                     desc=\"Loading test set\"):\n",
    "        sub_list = [sub for sub in os.listdir(path_center) if \"sub\" in sub]\n",
    "    \n",
    "        for subject in sub_list:\n",
    "            path_subject = os.path.join(path_center, subject, 'anat')        \n",
    "\n",
    "            acq_list = [acq for acq in os.listdir(path_subject) if \".nii.gz\" in acq]\n",
    "            for acq in acq_list:\n",
    "                path_acq = os.path.join(path_subject, acq)\n",
    "                if os.path.exists(path_acq):\n",
    "                    paths_acq.append(path_acq)\n",
    "                    labels.append(get_modality_path(path_acq))\n",
    "                \n",
    "    for path_acq in tqdm_notebook(paths_acq, unit = \"subject\"):\n",
    "        try:\n",
    "            pred = classify_acquisition(path_acq, model)\n",
    "        except RuntimeError:\n",
    "            labels.pop(paths_acq.index(path_acq))\n",
    "        else:\n",
    "            preds.append(pred)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    recall = recall_score(labels, preds, average=None)\n",
    "    precision = precision_score(labels, preds, average=None)\n",
    "\n",
    "    class_names = [\"MToff_MTS\", \"MTon_MTS\", \"T1w_MTS\", \"T1w\", \"T2star\", \"T2w\"]\n",
    "    # Plot normalized confusion matrix\n",
    "    plot_confusion_matrix(labels, preds, class_names)\n",
    "    plot_metrics(np.array([recall, precision]), accuracy, class_names)\n",
    "\n",
    "    return\n",
    "\n",
    "with open('config/config.json') as json_data:\n",
    "    context = json.load(json_data,)\n",
    "\n",
    "    test_model(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical accuracy evaluation\n",
    "\n",
    "Since we only measured the accuracy over each slice we have to measure the accuracy for a whole acquisition comprising several (at leat 15) tranches. If we consider the label that appears the most among the acquisition we obtain the estimated label for the acquisition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0,93\n",
    "\n",
    "def tirage(accuracy):\n",
    "    x = np.random.rand()\n",
    "    if x <= accuracy:\n",
    "        return([0,0,0,0,0,1])\n",
    "    else:\n",
    "        i = np.random.randint(4)\n",
    "        l = [0 for i in range(6)]\n",
    "        l[i] = 1\n",
    "        return(l)\n",
    "    \n",
    "def montecarlo(n, acc):\n",
    "    accuracy = 0\n",
    "    for i in range(n):\n",
    "        # we average over 15 slices\n",
    "        labels = [0 for i in range(6)]\n",
    "        for j in range(15):\n",
    "            t = tirage(acc)\n",
    "            labels = [x+y for x,y in zip(labels, t)]\n",
    "        label = labels.index(max(labels))\n",
    "        if label == 5:\n",
    "            accuracy += 1\n",
    "    return(100 * accuracy/n)\n",
    "            \n",
    "montecarlo(10000000, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we manage to obtain a promising 99.988% accuracy for each acquisition, which is enough for a reliable release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config_small.json') as fhandle:\n",
    "        context = json.load(fhandle)\n",
    "\n",
    "# Set the GPU\n",
    "gpu_number = int(0)\n",
    "torch.cuda.set_device(gpu_number)\n",
    "\n",
    "# These are the validation/testing transformations\n",
    "val_transform = transforms.Compose([\n",
    "    mt_transforms.CenterCrop2D((128, 128)),\n",
    "    mt_transforms.ToTensor(),\n",
    "    mt_transforms.NormalizeInstance(),\n",
    "])\n",
    "\n",
    "test_datasets = []\n",
    "for bids_ds in tqdm_notebook(context[\"bids_path_test\"], desc=\"Loading test set\"):\n",
    "    ds_test = BidsDataset(bids_ds,\n",
    "                                 transform=val_transform,\n",
    "                                 slice_filter_fn=SliceFilter())\n",
    "    test_datasets.append(ds_test)\n",
    "\n",
    "\n",
    "ds_test = ConcatDataset(test_datasets)\n",
    "print(f\"Loaded {len(ds_test)} axial slices for the test set.\")\n",
    "test_loader = DataLoader(ds_test, batch_size=context[\"batch_size\"],\n",
    "                         shuffle=False, pin_memory=True,\n",
    "                         collate_fn=mt_datasets.mt_collate,\n",
    "                         num_workers=1)\n",
    "\n",
    "print(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./\"+context[\"log_directory\"]+\"/best_model.pt\", map_location=\"cuda:0\")\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "a = torch.rand(3,1,128,128)\n",
    "a = a.cuda()\n",
    "\n",
    "model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ivado",
   "language": "python",
   "name": "ivado"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
