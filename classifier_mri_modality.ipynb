{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS Loader\n",
    "\n",
    "\n",
    "We use the data in `SpineGeneric`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bids_neuropoly import bids\n",
    "from medicaltorch import datasets as mt_datasets\n",
    "from medicaltorch import transforms as mt_transforms\n",
    "from medicaltorch import filters as mt_filters\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class SliceFilter(mt_filters.SliceFilter):\n",
    "    \"\"\"This class extends the SliceFilter that already\n",
    "    filters for empty labels and inputs. It will filter\n",
    "    slices that has only zeros after cropping. To avoid\n",
    "    feeding empty inputs into the network.\n",
    "    \"\"\"\n",
    "    def __call__(self, sample):\n",
    "        super_ret = super().__call__(sample)\n",
    "\n",
    "        # Already filtered by base class\n",
    "        if not super_ret:\n",
    "            return super_ret\n",
    "\n",
    "        # Filter slices where there are no values after cropping\n",
    "        input_img = Image.fromarray(sample['input'], mode='F')\n",
    "        input_cropped = transforms.functional.center_crop(input_img, (128, 128))\n",
    "        input_cropped = np.array(input_cropped)\n",
    "        count = np.count_nonzero(input_cropped)\n",
    "\n",
    "        if count <= 0:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "    \n",
    "class BIDSSegPair2D(mt_datasets.SegmentationPair2D):\n",
    "    def __init__(self, input_filename, gt_filename, metadata):\n",
    "        super().__init__(input_filename, gt_filename)\n",
    "        self.metadata = metadata\n",
    "        self.metadata[\"input_filename\"] = input_filename\n",
    "        self.metadata[\"gt_filename\"] = gt_filename\n",
    "\n",
    "    def get_pair_slice(self, slice_index, slice_axis=2):\n",
    "        dreturn = super().get_pair_slice(slice_index, slice_axis)\n",
    "        self.metadata[\"slice_index\"] = slice_index\n",
    "        dreturn[\"input_metadata\"][\"bids_metadata\"] = self.metadata\n",
    "        return dreturn\n",
    "\n",
    "\n",
    "class MRI2DBidsSegDataset(mt_datasets.MRI2DSegmentationDataset):\n",
    "    def _load_filenames(self):\n",
    "        for input_filename, gt_filename, bids_metadata in self.filename_pairs:\n",
    "            segpair = BIDSSegPair2D(input_filename, gt_filename,\n",
    "                                    bids_metadata)\n",
    "            self.handlers.append(segpair)\n",
    "\n",
    "\n",
    "class BidsDataset(MRI2DBidsSegDataset):\n",
    "    def __init__(self, root_dir, slice_axis=2, cache=True,\n",
    "                 transform=None, slice_filter_fn=None,\n",
    "                 canonical=False, labeled=True):\n",
    "        self.bids_ds = bids.BIDS(root_dir)\n",
    "        self.filename_pairs = []\n",
    "        self.metadata = {\"FlipAngle\": [], \"RepetitionTime\": [], \"EchoTime\": [], \"Manufacturer\": []}\n",
    "\n",
    "        for subject in self.bids_ds.get_subjects():\n",
    "\n",
    "            if not subject.has_derivative(\"labels\"):\n",
    "                print(\"Subject without derivative, skipping.\")\n",
    "                continue\n",
    "            derivatives = subject.get_derivatives(\"labels\")\n",
    "            cord_label_filename = None\n",
    "\n",
    "            for deriv in derivatives:\n",
    "                if deriv.endswith(\"seg-manual.nii.gz\"):\n",
    "                    cord_label_filename = deriv\n",
    "\n",
    "            if cord_label_filename is None:\n",
    "                continue\n",
    "\n",
    "            if not subject.has_metadata():\n",
    "                print(\"Subject without metadata.\")\n",
    "                continue\n",
    "\n",
    "            metadata = subject.metadata()\n",
    "            \n",
    "\n",
    "            self.filename_pairs.append((subject.record.absolute_path,\n",
    "                                        cord_label_filename, metadata))\n",
    "\n",
    "        super().__init__(self.filename_pairs, slice_axis, cache,\n",
    "                         transform, slice_filter_fn, canonical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Here we define the architecture of the network in a PyTorch Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DownConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, drop_rate=0.2, bn_momentum=0.1):\n",
    "        super(DownConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_ch, out_channels=out_ch, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_bn = nn.BatchNorm2d(out_ch, momentum=bn_momentum)\n",
    "        self.conv_drop = nn.Dropout2d(drop_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x))\n",
    "        x = self.conv_bn(x)\n",
    "        x = self.conv_drop(x)\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, drop_rate=0.2, bn_momentum=0.1):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv1 = DownConv(1, 32, drop_rate, bn_momentum)\n",
    "        self.mp1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv2 = DownConv(32, 32, drop_rate, bn_momentum)\n",
    "        self.mp2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv3 = DownConv(32, 64, drop_rate, bn_momentum)\n",
    "        self.mp3 = nn.MaxPool2d(2)       \n",
    "        \n",
    "        self.flat = Flatten()\n",
    "        self.dense1 = nn.Linear(16384, 512)\n",
    "        self.drop = nn.Dropout2d(drop_rate)\n",
    "        self.dense2 = nn.Linear(512, 6)\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.mp1(x1)\n",
    "        \n",
    "        x3 = self.conv2(x2)\n",
    "        x4 = self.mp2(x3)\n",
    "        \n",
    "        x5 = self.conv3(x4)\n",
    "        x6 = self.mp3(x5)\n",
    "        \n",
    "        x7 = self.flat(x6)\n",
    "        x8 = F.relu(self.dense1(x7))\n",
    "        x9 = self.drop(x8)\n",
    "        x10 = self.dense2(x9)\n",
    "        x11 = self.soft(x10)\n",
    "\n",
    "        return(x11)\n",
    "\n",
    "#torch tensors are of the format (batch_size, n_channels, shape_of_image)\n",
    "a = torch.rand(18,1,128,128)\n",
    "test = Classifier().forward(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import time\n",
    "import shutil\n",
    "import sys\n",
    "import pickle\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "\n",
    "\n",
    "def get_modality(batch):\n",
    "    labels = []\n",
    "    for acq in batch['input_metadata']:\n",
    "        path = acq.__getitem__('bids_metadata')['input_filename']\n",
    "        name = os.path.basename(path)\n",
    "        if \"acq-MToff_MTS\" in name :\n",
    "            labels.append(0)\n",
    "            continue\n",
    "        if \"acq-MTon_MTS\" in name :\n",
    "            labels.append(1)\n",
    "            continue\n",
    "        if \"acq-T1w_MTS\" in name :\n",
    "            labels.append(2)\n",
    "            continue\n",
    "        if \"T1w\" in name :\n",
    "            labels.append(3)\n",
    "            continue\n",
    "        if \"T2star\" in name :\n",
    "            labels.append(4)\n",
    "            continue\n",
    "        if \"T2w\" in name :\n",
    "            labels.append(5) \n",
    "            continue\n",
    "    return labels\n",
    "\n",
    "def OneHotEncode(labels):\n",
    "    ohe_labels = []\n",
    "    for label in labels :\n",
    "        ohe = [0 for i in range(6)]\n",
    "        ohe[label] = 1 \n",
    "        ohe_labels.append(ohe)\n",
    "    return torch.cuda.FloatTensor(ohe_labels)\n",
    "\n",
    "\n",
    "def cmd_train(context):\n",
    "    \"\"\"Main command do train the network.\n",
    "    :param context: this is a dictionary with all data from the\n",
    "                    configuration file:\n",
    "                        - 'command': run the specified command (e.g. train, test)\n",
    "                        - 'gpu': ID of the used GPU\n",
    "                        - 'bids_path_train': list of relative paths of the BIDS folders of each training center\n",
    "                        - 'bids_path_validation': list of relative paths of the BIDS folders of each validation center\n",
    "                        - 'bids_path_test': list of relative paths of the BIDS folders of each test center\n",
    "                        - 'batch_size'\n",
    "                        - 'dropout_rate'\n",
    "                        - 'batch_norm_momentum'\n",
    "                        - 'num_epochs'\n",
    "                        - 'initial_lr': initial learning rate\n",
    "                        - 'log_directory': folder name where log files are saved\n",
    "                        - 'debugging': allows extended verbosity and intermediate outputs\n",
    "    \"\"\"\n",
    "    # Set the GPU\n",
    "    gpu_number = int(0)\n",
    "    torch.cuda.set_device(gpu_number)\n",
    "\n",
    "    # These are the training transformations\n",
    "    train_transform = transforms.Compose([\n",
    "        mt_transforms.CenterCrop2D((128, 128)),\n",
    "        mt_transforms.ElasticTransform(alpha_range=(28.0, 30.0),\n",
    "                                       sigma_range=(3.5, 4.0),\n",
    "                                       p=0.3),\n",
    "        mt_transforms.RandomAffine(degrees=4.6,\n",
    "                                   scale=(0.98, 1.02),\n",
    "                                   translate=(0.03, 0.03)),\n",
    "        mt_transforms.RandomTensorChannelShift((-0.10, 0.10)),\n",
    "        mt_transforms.ToTensor(),\n",
    "        mt_transforms.NormalizeInstance(),\n",
    "    ])\n",
    "\n",
    "    # These are the validation/testing transformations\n",
    "    val_transform = transforms.Compose([\n",
    "        mt_transforms.CenterCrop2D((128, 128)),\n",
    "        mt_transforms.ToTensor(),\n",
    "        mt_transforms.NormalizeInstance(),\n",
    "    ])\n",
    "\n",
    "    # This code will iterate over the folders and load the data, filtering\n",
    "    # the slices without labels and then concatenating all the datasets together\n",
    "    train_datasets = []\n",
    "    for bids_ds in tqdm_notebook(context[\"bids_path_train\"], desc=\"Loading training set\"):\n",
    "        ds_train = BidsDataset(bids_ds,\n",
    "                               transform=train_transform,\n",
    "                               slice_filter_fn=SliceFilter())\n",
    "        train_datasets.append(ds_train)\n",
    "\n",
    "    ds_train = ConcatDataset(train_datasets)\n",
    "    print(f\"Loaded {len(ds_train)} axial slices for the training set.\")\n",
    "    train_loader = DataLoader(ds_train, batch_size=context[\"batch_size\"],\n",
    "                              shuffle=True, pin_memory=True,\n",
    "                              collate_fn=mt_datasets.mt_collate,\n",
    "                              num_workers=1)\n",
    "    \n",
    "    # Validation dataset ------------------------------------------------------\n",
    "    validation_datasets = []\n",
    "    for bids_ds in tqdm_notebook(context[\"bids_path_validation\"], desc=\"Loading validation set\"):\n",
    "        ds_val = BidsDataset(bids_ds,\n",
    "                             transform=val_transform,\n",
    "                             slice_filter_fn=SliceFilter())\n",
    "        validation_datasets.append(ds_val)\n",
    "\n",
    "    ds_val = ConcatDataset(validation_datasets)\n",
    "    print(f\"Loaded {len(ds_val)} axial slices for the validation set.\")\n",
    "    val_loader = DataLoader(ds_val, batch_size=context[\"batch_size\"],\n",
    "                            shuffle=True, pin_memory=True,\n",
    "                            collate_fn=mt_datasets.mt_collate,\n",
    "                            num_workers=0)\n",
    "    \n",
    "    \n",
    "    # Model definition ---------------------------------------------------------\n",
    "    model = Classifier(drop_rate=context[\"dropout_rate\"],\n",
    "                       bn_momentum=context[\"batch_norm_momentum\"])\n",
    "\n",
    "    model.cuda()\n",
    "\n",
    "    num_epochs = context[\"num_epochs\"]\n",
    "    initial_lr = context[\"initial_lr\"]\n",
    "\n",
    "    # Using SGD with cosine annealing learning rate\n",
    "    optimizer = optim.SGD(model.parameters(), lr=initial_lr)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)\n",
    "\n",
    "    # Write the metrics, images, etc to TensorBoard format\n",
    "    writer = SummaryWriter(log_dir=context[\"log_directory\"])\n",
    "    \n",
    "    # Binary Cross Entropy Loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    \n",
    "    # Training loop -----------------------------------------------------------\n",
    "    best_validation_loss = float(\"inf\")\n",
    "    \n",
    "    lst_train_loss = []\n",
    "    lst_val_loss = []\n",
    "    lst_accuracy = []\n",
    "    \n",
    "    for epoch in tqdm_notebook(range(1, num_epochs+1), desc=\"Training\"):\n",
    "        start_time = time.time()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        lr = scheduler.get_lr()[0]\n",
    "        writer.add_scalar('learning_rate', lr, epoch)\n",
    "\n",
    "        model.train()\n",
    "        train_loss_total = 0.0\n",
    "        num_steps = 0\n",
    "    \n",
    "        for i, batch in enumerate(train_loader):\n",
    "            input_samples = batch[\"input\"]\n",
    "            input_labels = get_modality(batch)\n",
    "            \n",
    "            var_input = input_samples.cuda()\n",
    "            var_labels = torch.cuda.LongTensor(input_labels).cuda(non_blocking=True)\n",
    "\n",
    "            outputs = model(var_input)\n",
    "            \n",
    "            loss = criterion(outputs, var_labels)\n",
    "            train_loss_total += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            num_steps += 1\n",
    "            \n",
    "        train_loss_total_avg = train_loss_total / num_steps\n",
    "        lst_train_loss.append(train_loss_total_avg)\n",
    "        \n",
    "        #tqdm.write(f\"Epoch {epoch} training loss: {train_loss_total_avg:.4f}.\")\n",
    "        print(f\"Epoch {epoch} training loss: {train_loss_total_avg:.4f}.\")\n",
    "        \n",
    "        \n",
    "        # Validation loop -----------------------------------------------------\n",
    "        model.eval()\n",
    "        val_loss_total = 0.0\n",
    "        num_steps = 0\n",
    "        \n",
    "        val_accuracy = 0\n",
    "        num_samples = 0\n",
    "        \n",
    "        for i, batch in enumerate(val_loader):\n",
    "            input_samples = batch[\"input\"]\n",
    "            input_labels = get_modality(batch)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                var_input = input_samples.cuda()\n",
    "                var_labels = torch.cuda.LongTensor(input_labels).cuda(non_blocking=True)\n",
    "\n",
    "                outputs = model(var_input)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                loss = criterion(outputs, var_labels)\n",
    "                val_loss_total += loss.item()\n",
    "                \n",
    "                val_accuracy += int((var_labels == preds).sum())\n",
    "                \n",
    "            num_steps += 1\n",
    "            num_samples += context['batch_size']\n",
    "            \n",
    "        val_loss_total_avg = val_loss_total / num_steps\n",
    "        lst_val_loss.append(val_loss_total_avg)\n",
    "        \n",
    "        #tqdm.write(f\"Epoch {epoch} validation loss: {val_loss_total_avg:.4f}.\")\n",
    "        print(f\"Epoch {epoch} validation loss: {val_loss_total_avg:.4f}.\")\n",
    "        \n",
    "        val_accuracy_avg = 100 * val_accuracy / num_samples\n",
    "        lst_accuracy.append(val_accuracy_avg)\n",
    "        \n",
    "        #tqdm.write(f\"Epoch {epoch} accuracy : {val_accuracy_avg:.4f}.\")\n",
    "        print(f\"Epoch {epoch} accuracy : {val_accuracy_avg:.4f} %.\")\n",
    "        \n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        #tqdm.write(\"Epoch {} took {:.2f} seconds.\".format(epoch, total_time))\n",
    "        print(\"Epoch {} took {:.2f} seconds.\".format(epoch, total_time))\n",
    "        \n",
    "        \n",
    "        if val_loss_total_avg < best_validation_loss:\n",
    "            best_validation_loss = val_loss_total_avg\n",
    "            torch.save(model, \"./\"+context[\"log_directory\"]+\"/best_model.pt\")\n",
    "\n",
    "        \n",
    "    # save final model\n",
    "    torch.save(model, \"./\"+context[\"log_directory\"]+\"/final_model.pt\")\n",
    "    \n",
    "    # display and save the metrics\n",
    "    parameters = \"CrossEntropyLoss, batchsize=\" + str(context['batch_size'])\n",
    "    parameters += \", initial_lr=\" + str(context['initial_lr'])\n",
    "    parameters += \", dropout=\" + str(context['dropout_rate'])\n",
    "    \n",
    "    \n",
    "    plt.subplot(2,1,1)\n",
    "    plt.title(parameters)\n",
    "    plt.plot(lst_train_loss, color='red', label='Training')\n",
    "    plt.plot(lst_val_loss, color='blue', label='Validation')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(lst_accuracy)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    \n",
    "    plt.savefig(parameters+'.png')\n",
    "    plt.show()    \n",
    "    return\n",
    "\n",
    "\n",
    "def run_main(command):\n",
    "    with open('config_small.json') as fhandle:\n",
    "        context = json.load(fhandle)\n",
    "\n",
    "    #command = context[\"command\"]\n",
    "\n",
    "    if command == 'train':\n",
    "        cmd_train(context)\n",
    "        #shutil.copyfile(sys.argv[1], \"./\"+context[\"log_directory\"]+\"/config_file.json\")\n",
    "    elif command == 'test':\n",
    "        cmd_test(context)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb4acd72d7d445681385b1f86d11250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading training set', max=6, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3518 axial slices for the training set.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ed4b615d8547e2862b5307eb7ae519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading validation set', max=4, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2948 axial slices for the validation set.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019a9cc401404fb6ae39aae6d9be80a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=50, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 training loss: 1.4957.\n",
      "Epoch 1 validation loss: 1.4231.\n",
      "Epoch 1 accuracy : 68.3784 %.\n",
      "Epoch 1 took 37.71 seconds.\n",
      "Epoch 2 training loss: 1.2851.\n",
      "Epoch 2 validation loss: 1.3445.\n",
      "Epoch 2 accuracy : 71.8243 %.\n",
      "Epoch 2 took 37.19 seconds.\n",
      "Epoch 3 training loss: 1.2125.\n",
      "Epoch 3 validation loss: 1.3092.\n",
      "Epoch 3 accuracy : 75.2027 %.\n",
      "Epoch 3 took 37.40 seconds.\n",
      "Epoch 4 training loss: 1.1815.\n",
      "Epoch 4 validation loss: 1.2939.\n",
      "Epoch 4 accuracy : 75.1689 %.\n",
      "Epoch 4 took 37.73 seconds.\n",
      "Epoch 5 training loss: 1.1624.\n",
      "Epoch 5 validation loss: 1.2612.\n",
      "Epoch 5 accuracy : 78.7838 %.\n",
      "Epoch 5 took 37.61 seconds.\n",
      "Epoch 6 training loss: 1.1462.\n",
      "Epoch 6 validation loss: 1.2526.\n",
      "Epoch 6 accuracy : 80.0676 %.\n",
      "Epoch 6 took 37.74 seconds.\n",
      "Epoch 7 training loss: 1.1396.\n",
      "Epoch 7 validation loss: 1.2255.\n",
      "Epoch 7 accuracy : 82.2297 %.\n",
      "Epoch 7 took 37.46 seconds.\n",
      "Epoch 8 training loss: 1.1300.\n",
      "Epoch 8 validation loss: 1.2319.\n",
      "Epoch 8 accuracy : 81.4527 %.\n",
      "Epoch 8 took 37.41 seconds.\n",
      "Epoch 9 training loss: 1.1214.\n",
      "Epoch 9 validation loss: 1.2116.\n",
      "Epoch 9 accuracy : 83.7500 %.\n",
      "Epoch 9 took 37.53 seconds.\n",
      "Epoch 10 training loss: 1.1175.\n",
      "Epoch 10 validation loss: 1.2298.\n",
      "Epoch 10 accuracy : 81.2838 %.\n",
      "Epoch 10 took 37.29 seconds.\n",
      "Epoch 11 training loss: 1.1083.\n",
      "Epoch 11 validation loss: 1.1963.\n",
      "Epoch 11 accuracy : 85.5405 %.\n",
      "Epoch 11 took 37.53 seconds.\n",
      "Epoch 12 training loss: 1.1029.\n",
      "Epoch 12 validation loss: 1.1782.\n",
      "Epoch 12 accuracy : 87.2635 %.\n",
      "Epoch 12 took 37.84 seconds.\n",
      "Epoch 13 training loss: 1.0986.\n",
      "Epoch 13 validation loss: 1.1991.\n",
      "Epoch 13 accuracy : 84.8311 %.\n",
      "Epoch 13 took 37.51 seconds.\n",
      "Epoch 14 training loss: 1.0961.\n",
      "Epoch 14 validation loss: 1.1778.\n",
      "Epoch 14 accuracy : 87.0608 %.\n",
      "Epoch 14 took 37.76 seconds.\n",
      "Epoch 15 training loss: 1.0941.\n",
      "Epoch 15 validation loss: 1.1663.\n",
      "Epoch 15 accuracy : 88.1757 %.\n",
      "Epoch 15 took 37.90 seconds.\n",
      "Epoch 16 training loss: 1.0923.\n",
      "Epoch 16 validation loss: 1.1810.\n",
      "Epoch 16 accuracy : 86.8243 %.\n",
      "Epoch 16 took 37.82 seconds.\n",
      "Epoch 17 training loss: 1.0890.\n",
      "Epoch 17 validation loss: 1.1647.\n",
      "Epoch 17 accuracy : 87.9730 %.\n",
      "Epoch 17 took 37.86 seconds.\n",
      "Epoch 18 training loss: 1.0807.\n",
      "Epoch 18 validation loss: 1.1713.\n",
      "Epoch 18 accuracy : 87.5000 %.\n",
      "Epoch 18 took 37.72 seconds.\n",
      "Epoch 19 training loss: 1.0826.\n",
      "Epoch 19 validation loss: 1.1617.\n",
      "Epoch 19 accuracy : 88.3784 %.\n",
      "Epoch 19 took 37.86 seconds.\n",
      "Epoch 20 training loss: 1.0772.\n",
      "Epoch 20 validation loss: 1.1666.\n",
      "Epoch 20 accuracy : 87.7027 %.\n",
      "Epoch 20 took 37.53 seconds.\n",
      "Epoch 21 training loss: 1.0771.\n",
      "Epoch 21 validation loss: 1.1702.\n",
      "Epoch 21 accuracy : 87.6689 %.\n",
      "Epoch 21 took 37.38 seconds.\n",
      "Epoch 22 training loss: 1.0747.\n",
      "Epoch 22 validation loss: 1.1712.\n",
      "Epoch 22 accuracy : 87.2973 %.\n",
      "Epoch 22 took 37.33 seconds.\n",
      "Epoch 23 training loss: 1.0756.\n",
      "Epoch 23 validation loss: 1.1756.\n",
      "Epoch 23 accuracy : 86.8243 %.\n",
      "Epoch 23 took 37.24 seconds.\n",
      "Epoch 24 training loss: 1.0742.\n",
      "Epoch 24 validation loss: 1.1628.\n",
      "Epoch 24 accuracy : 88.1419 %.\n",
      "Epoch 24 took 37.44 seconds.\n",
      "Epoch 25 training loss: 1.0752.\n",
      "Epoch 25 validation loss: 1.1593.\n",
      "Epoch 25 accuracy : 88.2432 %.\n",
      "Epoch 25 took 37.45 seconds.\n",
      "Epoch 26 training loss: 1.0751.\n",
      "Epoch 26 validation loss: 1.1430.\n",
      "Epoch 26 accuracy : 89.8311 %.\n",
      "Epoch 26 took 37.27 seconds.\n",
      "Epoch 27 training loss: 1.0703.\n",
      "Epoch 27 validation loss: 1.1630.\n",
      "Epoch 27 accuracy : 87.8716 %.\n",
      "Epoch 27 took 37.61 seconds.\n",
      "Epoch 28 training loss: 1.0701.\n",
      "Epoch 28 validation loss: 1.1450.\n",
      "Epoch 28 accuracy : 89.5946 %.\n",
      "Epoch 28 took 37.65 seconds.\n",
      "Epoch 29 training loss: 1.0699.\n",
      "Epoch 29 validation loss: 1.1498.\n",
      "Epoch 29 accuracy : 89.1216 %.\n",
      "Epoch 29 took 37.24 seconds.\n",
      "Epoch 30 training loss: 1.0725.\n",
      "Epoch 30 validation loss: 1.1626.\n",
      "Epoch 30 accuracy : 87.8378 %.\n",
      "Epoch 30 took 38.00 seconds.\n",
      "Epoch 31 training loss: 1.0705.\n",
      "Epoch 31 validation loss: 1.1460.\n",
      "Epoch 31 accuracy : 89.8986 %.\n",
      "Epoch 31 took 37.78 seconds.\n",
      "Epoch 32 training loss: 1.0672.\n",
      "Epoch 32 validation loss: 1.1366.\n",
      "Epoch 32 accuracy : 90.4054 %.\n",
      "Epoch 32 took 37.70 seconds.\n",
      "Epoch 33 training loss: 1.0682.\n",
      "Epoch 33 validation loss: 1.1466.\n",
      "Epoch 33 accuracy : 89.3919 %.\n",
      "Epoch 33 took 37.71 seconds.\n",
      "Epoch 34 training loss: 1.0680.\n",
      "Epoch 34 validation loss: 1.1387.\n",
      "Epoch 34 accuracy : 90.3041 %.\n",
      "Epoch 34 took 37.92 seconds.\n",
      "Epoch 35 training loss: 1.0646.\n",
      "Epoch 35 validation loss: 1.1414.\n",
      "Epoch 35 accuracy : 89.8986 %.\n",
      "Epoch 35 took 37.78 seconds.\n",
      "Epoch 36 training loss: 1.0692.\n",
      "Epoch 36 validation loss: 1.1441.\n",
      "Epoch 36 accuracy : 89.6284 %.\n",
      "Epoch 36 took 37.65 seconds.\n",
      "Epoch 37 training loss: 1.0666.\n",
      "Epoch 37 validation loss: 1.1433.\n",
      "Epoch 37 accuracy : 89.8311 %.\n",
      "Epoch 37 took 37.67 seconds.\n",
      "Epoch 38 training loss: 1.0679.\n",
      "Epoch 38 validation loss: 1.1500.\n",
      "Epoch 38 accuracy : 89.3581 %.\n",
      "Epoch 38 took 37.85 seconds.\n",
      "Epoch 39 training loss: 1.0654.\n",
      "Epoch 39 validation loss: 1.1474.\n",
      "Epoch 39 accuracy : 89.4932 %.\n",
      "Epoch 39 took 37.54 seconds.\n",
      "Epoch 40 training loss: 1.0668.\n",
      "Epoch 40 validation loss: 1.1451.\n",
      "Epoch 40 accuracy : 89.5608 %.\n",
      "Epoch 40 took 37.49 seconds.\n",
      "Epoch 41 training loss: 1.0665.\n",
      "Epoch 41 validation loss: 1.1491.\n",
      "Epoch 41 accuracy : 89.2568 %.\n",
      "Epoch 41 took 37.45 seconds.\n",
      "Epoch 42 training loss: 1.0634.\n",
      "Epoch 42 validation loss: 1.1505.\n",
      "Epoch 42 accuracy : 89.1216 %.\n",
      "Epoch 42 took 37.27 seconds.\n",
      "Epoch 43 training loss: 1.0635.\n",
      "Epoch 43 validation loss: 1.1484.\n",
      "Epoch 43 accuracy : 89.2905 %.\n",
      "Epoch 43 took 37.38 seconds.\n",
      "Epoch 44 training loss: 1.0658.\n",
      "Epoch 44 validation loss: 1.1499.\n",
      "Epoch 44 accuracy : 88.9865 %.\n",
      "Epoch 44 took 37.43 seconds.\n",
      "Epoch 45 training loss: 1.0674.\n",
      "Epoch 45 validation loss: 1.1492.\n",
      "Epoch 45 accuracy : 89.1892 %.\n",
      "Epoch 45 took 37.39 seconds.\n",
      "Epoch 46 training loss: 1.0669.\n",
      "Epoch 46 validation loss: 1.1469.\n",
      "Epoch 46 accuracy : 89.3581 %.\n",
      "Epoch 46 took 37.74 seconds.\n",
      "Epoch 47 training loss: 1.0643.\n",
      "Epoch 47 validation loss: 1.1463.\n",
      "Epoch 47 accuracy : 89.4595 %.\n",
      "Epoch 47 took 38.16 seconds.\n",
      "Epoch 48 training loss: 1.0639.\n",
      "Epoch 48 validation loss: 1.1485.\n",
      "Epoch 48 accuracy : 89.1216 %.\n",
      "Epoch 48 took 38.02 seconds.\n",
      "Epoch 49 training loss: 1.0663.\n",
      "Epoch 49 validation loss: 1.1499.\n",
      "Epoch 49 accuracy : 89.1554 %.\n",
      "Epoch 49 took 37.89 seconds.\n",
      "Epoch 50 training loss: 1.0646.\n",
      "Epoch 50 validation loss: 1.1528.\n",
      "Epoch 50 accuracy : 89.0541 %.\n",
      "Epoch 50 took 37.91 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_main('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy evaluation\n",
    "\n",
    "Since we only measured the accuracy over each slice we have to measure the accuracy for a whole acquisition comprising several (at leat 15) tranches. If we consider the label that appears the most among the acquisition we obtain the estimated label for the acquisition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.99884"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tirage():\n",
    "    x = np.random.rand()\n",
    "    if x <= 0.84:\n",
    "        return([0,0,0,0,0,1])\n",
    "    else:\n",
    "        i = np.random.randint(4)\n",
    "        l = [0 for i in range(6)]\n",
    "        l[i] = 1\n",
    "        return(l)\n",
    "    \n",
    "def montecarlo(n):\n",
    "    accuracy = 0\n",
    "    for i in range(n):\n",
    "        # we average over 15 slices\n",
    "        labels = [0 for i in range(6)]\n",
    "        for j in range(15):\n",
    "            t = tirage()\n",
    "            labels = [x+y for x,y in zip(labels, t)]\n",
    "        label = labels.index(max(labels))\n",
    "        if label == 5:\n",
    "            accuracy += 1\n",
    "    return(100 * accuracy/n)\n",
    "            \n",
    "montecarlo(10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we manage to obtain a promising 99.988% accuracy for each acquisition, which is enough for a reliable release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config_small.json') as fhandle:\n",
    "    context = json.load(fhandle)\n",
    "\n",
    "command = context[\"command\"]\n",
    "\n",
    "if command == 'train':\n",
    "    cmd_train(context)\n",
    "    shutil.copyfile(sys.argv[1], \"./\"+context[\"log_directory\"]+\"/config_file.json\")\n",
    "elif command == 'test':\n",
    "    cmd_test(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds = torch.rand(18,6)\n",
    "preds_norm = nn.Softmax()\n",
    "labels = [4, 5, 1, 3, 2, 5, 2, 5, 0, 3, 1, 0, 4, 0, 3, 0, 5, 3]\n",
    "var_labels = []\n",
    "for l in labels :\n",
    "    a = [0 for i in range(6)]\n",
    "    a[l] = 1 \n",
    "    var_labels.append(a)\n",
    "var_labels = torch.FloatTensor(var_labels)\n",
    "\n",
    "\n",
    "\n",
    "CS_loss = nn.BCELoss()\n",
    "loss = CS_loss(var_labels, preds)\n",
    "\n",
    "NLL = nn.NLLLoss()\n",
    "loss = NLL(var_labels, preds)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    a = torch.rand(18,1,128,128)\n",
    "    a = a.cuda()\n",
    "    t = time.time()\n",
    "            \n",
    "    preds = model(a)\n",
    "\n",
    "    print(f\"took {time.time() - t} to compute\")\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ivado",
   "language": "python",
   "name": "ivado"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
