{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS Loader\n",
    "\n",
    "\n",
    "We use the data in `SpineGeneric`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bids_neuropoly import bids\n",
    "from medicaltorch import datasets as mt_datasets\n",
    "from medicaltorch import transforms as mt_transforms\n",
    "from medicaltorch import filters as mt_filters\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class SliceFilter(mt_filters.SliceFilter):\n",
    "    \"\"\"This class extends the SliceFilter that already\n",
    "    filters for empty labels and inputs. It will filter\n",
    "    slices that has only zeros after cropping. To avoid\n",
    "    feeding empty inputs into the network.\n",
    "    \"\"\"\n",
    "    def __call__(self, sample):\n",
    "        super_ret = super().__call__(sample)\n",
    "\n",
    "        # Already filtered by base class\n",
    "        if not super_ret:\n",
    "            return super_ret\n",
    "\n",
    "        # Filter slices where there are no values after cropping\n",
    "        input_img = Image.fromarray(sample['input'], mode='F')\n",
    "        input_cropped = transforms.functional.center_crop(input_img, (128, 128))\n",
    "        input_cropped = np.array(input_cropped)\n",
    "        count = np.count_nonzero(input_cropped)\n",
    "\n",
    "        if count <= 0:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "    \n",
    "class BIDSSegPair2D(mt_datasets.SegmentationPair2D):\n",
    "    def __init__(self, input_filename, gt_filename, metadata):\n",
    "        super().__init__(input_filename, gt_filename)\n",
    "        self.metadata = metadata\n",
    "        self.metadata[\"input_filename\"] = input_filename\n",
    "        self.metadata[\"gt_filename\"] = gt_filename\n",
    "\n",
    "    def get_pair_slice(self, slice_index, slice_axis=2):\n",
    "        dreturn = super().get_pair_slice(slice_index, slice_axis)\n",
    "        self.metadata[\"slice_index\"] = slice_index\n",
    "        dreturn[\"input_metadata\"][\"bids_metadata\"] = self.metadata\n",
    "        return dreturn\n",
    "\n",
    "\n",
    "class MRI2DBidsSegDataset(mt_datasets.MRI2DSegmentationDataset):\n",
    "    def _load_filenames(self):\n",
    "        for input_filename, gt_filename, bids_metadata in self.filename_pairs:\n",
    "            segpair = BIDSSegPair2D(input_filename, gt_filename,\n",
    "                                    bids_metadata)\n",
    "            self.handlers.append(segpair)\n",
    "\n",
    "\n",
    "class BidsDataset(MRI2DBidsSegDataset):\n",
    "    def __init__(self, root_dir, slice_axis=2, cache=True,\n",
    "                 transform=None, slice_filter_fn=None,\n",
    "                 canonical=False, labeled=True):\n",
    "        self.bids_ds = bids.BIDS(root_dir)\n",
    "        self.filename_pairs = []\n",
    "        self.metadata = {\"FlipAngle\": [], \"RepetitionTime\": [], \"EchoTime\": [], \"Manufacturer\": []}\n",
    "\n",
    "        for subject in self.bids_ds.get_subjects():\n",
    "\n",
    "            if not subject.has_derivative(\"labels\"):\n",
    "                print(\"Subject without derivative, skipping.\")\n",
    "                continue\n",
    "            derivatives = subject.get_derivatives(\"labels\")\n",
    "            cord_label_filename = None\n",
    "\n",
    "            for deriv in derivatives:\n",
    "                if deriv.endswith(\"seg-manual.nii.gz\"):\n",
    "                    cord_label_filename = deriv\n",
    "\n",
    "            if cord_label_filename is None:\n",
    "                continue\n",
    "\n",
    "            if not subject.has_metadata():\n",
    "                print(\"Subject without metadata.\")\n",
    "                continue\n",
    "\n",
    "            metadata = subject.metadata()\n",
    "            \n",
    "\n",
    "            self.filename_pairs.append((subject.record.absolute_path,\n",
    "                                        cord_label_filename, metadata))\n",
    "\n",
    "        super().__init__(self.filename_pairs, slice_axis, cache,\n",
    "                         transform, slice_filter_fn, canonical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torchvision.transforms.functional.center_crop(img, output_size)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_transforms.F.center_crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Here we define the architecture of the network in a PyTorch Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DownConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, drop_rate=0.2, bn_momentum=0.1):\n",
    "        super(DownConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_ch, out_channels=out_ch, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_bn = nn.BatchNorm2d(out_ch, momentum=bn_momentum)\n",
    "        self.conv_drop = nn.Dropout2d(drop_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x))\n",
    "        x = self.conv_bn(x)\n",
    "        x = self.conv_drop(x)\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, drop_rate=0.2, bn_momentum=0.1):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv1 = DownConv(1, 32, drop_rate, bn_momentum)\n",
    "        self.mp1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv2 = DownConv(32, 32, drop_rate, bn_momentum)\n",
    "        self.mp2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv3 = DownConv(32, 64, drop_rate, bn_momentum)\n",
    "        self.mp3 = nn.MaxPool2d(2)       \n",
    "        \n",
    "        self.flat = Flatten()\n",
    "        self.dense1 = nn.Linear(16384, 512)\n",
    "        self.drop = nn.Dropout2d(drop_rate)\n",
    "        self.dense2 = nn.Linear(512, 6)\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.mp1(x1)\n",
    "        \n",
    "        x3 = self.conv2(x2)\n",
    "        x4 = self.mp2(x3)\n",
    "        \n",
    "        x5 = self.conv3(x4)\n",
    "        x6 = self.mp3(x5)\n",
    "        \n",
    "        x7 = self.flat(x6)\n",
    "        x8 = F.relu(self.dense1(x7))\n",
    "        x9 = self.drop(x8)\n",
    "        x10 = self.dense2(x9)\n",
    "        x11 = self.soft(x10)\n",
    "\n",
    "        return(x11)\n",
    "\n",
    "#torch tensors are of the format (batch_size, n_channels, shape_of_image)\n",
    "a = torch.rand(18,1,128,128)\n",
    "test = Classifier().forward(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import time\n",
    "import shutil\n",
    "import sys\n",
    "import pickle\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "\n",
    "\n",
    "def get_modality(batch):\n",
    "    labels = []\n",
    "    for acq in batch['input_metadata']:\n",
    "        path = acq.__getitem__('bids_metadata')['input_filename']\n",
    "        name = os.path.basename(path)\n",
    "        if \"acq-MToff_MTS\" in name :\n",
    "            labels.append(0)\n",
    "            continue\n",
    "        if \"acq-MTon_MTS\" in name :\n",
    "            labels.append(1)\n",
    "            continue\n",
    "        if \"acq-T1w_MTS\" in name :\n",
    "            labels.append(2)\n",
    "            continue\n",
    "        if \"T1w\" in name :\n",
    "            labels.append(3)\n",
    "            continue\n",
    "        if \"T2star\" in name :\n",
    "            labels.append(4)\n",
    "            continue\n",
    "        if \"T2w\" in name :\n",
    "            labels.append(5) \n",
    "            continue\n",
    "    return labels\n",
    "\n",
    "def OneHotEncode(labels):\n",
    "    ohe_labels = []\n",
    "    for label in labels :\n",
    "        ohe = [0 for i in range(6)]\n",
    "        ohe[label] = 1 \n",
    "        ohe_labels.append(ohe)\n",
    "    return torch.cuda.FloatTensor(ohe_labels)\n",
    "\n",
    "\n",
    "def cmd_train(context):\n",
    "    \"\"\"Main command do train the network.\n",
    "    :param context: this is a dictionary with all data from the\n",
    "                    configuration file:\n",
    "                        - 'command': run the specified command (e.g. train, test)\n",
    "                        - 'gpu': ID of the used GPU\n",
    "                        - 'bids_path_train': list of relative paths of the BIDS folders of each training center\n",
    "                        - 'bids_path_validation': list of relative paths of the BIDS folders of each validation center\n",
    "                        - 'bids_path_test': list of relative paths of the BIDS folders of each test center\n",
    "                        - 'batch_size'\n",
    "                        - 'dropout_rate'\n",
    "                        - 'batch_norm_momentum'\n",
    "                        - 'num_epochs'\n",
    "                        - 'initial_lr': initial learning rate\n",
    "                        - 'log_directory': folder name where log files are saved\n",
    "                        - 'debugging': allows extended verbosity and intermediate outputs\n",
    "    \"\"\"\n",
    "    # Set the GPU\n",
    "    gpu_number = int(0)\n",
    "    torch.cuda.set_device(gpu_number)\n",
    "\n",
    "    # These are the training transformations\n",
    "    train_transform = transforms.Compose([\n",
    "        mt_transforms.CenterCrop2D((128, 128)),\n",
    "        mt_transforms.ElasticTransform(alpha_range=(28.0, 30.0),\n",
    "                                       sigma_range=(3.5, 4.0),\n",
    "                                       p=0.3),\n",
    "        mt_transforms.RandomAffine(degrees=4.6,\n",
    "                                   scale=(0.98, 1.02),\n",
    "                                   translate=(0.03, 0.03)),\n",
    "        mt_transforms.RandomTensorChannelShift((-0.10, 0.10)),\n",
    "        mt_transforms.ToTensor(),\n",
    "        mt_transforms.NormalizeInstance(),\n",
    "    ])\n",
    "\n",
    "    # These are the validation/testing transformations\n",
    "    val_transform = transforms.Compose([\n",
    "        mt_transforms.CenterCrop2D((128, 128)),\n",
    "        mt_transforms.ToTensor(),\n",
    "        mt_transforms.NormalizeInstance(),\n",
    "    ])\n",
    "\n",
    "    # This code will iterate over the folders and load the data, filtering\n",
    "    # the slices without labels and then concatenating all the datasets together\n",
    "    train_datasets = []\n",
    "    for bids_ds in tqdm_notebook(context[\"bids_path_train\"], desc=\"Loading training set\"):\n",
    "        ds_train = BidsDataset(bids_ds,\n",
    "                               transform=train_transform,\n",
    "                               slice_filter_fn=SliceFilter())\n",
    "        train_datasets.append(ds_train)\n",
    "\n",
    "    ds_train = ConcatDataset(train_datasets)\n",
    "    print(f\"Loaded {len(ds_train)} axial slices for the training set.\")\n",
    "    train_loader = DataLoader(ds_train, batch_size=context[\"batch_size\"],\n",
    "                              shuffle=True, pin_memory=True,\n",
    "                              collate_fn=mt_datasets.mt_collate,\n",
    "                              num_workers=1)\n",
    "    \n",
    "    # Validation dataset ------------------------------------------------------\n",
    "    validation_datasets = []\n",
    "    for bids_ds in tqdm_notebook(context[\"bids_path_validation\"], desc=\"Loading validation set\"):\n",
    "        ds_val = BidsDataset(bids_ds,\n",
    "                             transform=val_transform,\n",
    "                             slice_filter_fn=SliceFilter())\n",
    "        validation_datasets.append(ds_val)\n",
    "\n",
    "    ds_val = ConcatDataset(validation_datasets)\n",
    "    print(f\"Loaded {len(ds_val)} axial slices for the validation set.\")\n",
    "    val_loader = DataLoader(ds_val, batch_size=context[\"batch_size\"],\n",
    "                            shuffle=True, pin_memory=True,\n",
    "                            collate_fn=mt_datasets.mt_collate,\n",
    "                            num_workers=0)\n",
    "    \n",
    "    \n",
    "    # Model definition ---------------------------------------------------------\n",
    "    model = Classifier(drop_rate=context[\"dropout_rate\"],\n",
    "                       bn_momentum=context[\"batch_norm_momentum\"])\n",
    "\n",
    "    model.cuda()\n",
    "\n",
    "    num_epochs = context[\"num_epochs\"]\n",
    "    initial_lr = context[\"initial_lr\"]\n",
    "\n",
    "    # Using SGD with cosine annealing learning rate\n",
    "    optimizer = optim.SGD(model.parameters(), lr=initial_lr)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)\n",
    "\n",
    "    # Write the metrics, images, etc to TensorBoard format\n",
    "    writer = SummaryWriter(log_dir=context[\"log_directory\"])\n",
    "    \n",
    "    # Binary Cross Entropy Loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    \n",
    "    # Training loop -----------------------------------------------------------\n",
    "    best_validation_loss = float(\"inf\")\n",
    "    \n",
    "    lst_train_loss = []\n",
    "    lst_val_loss = []\n",
    "    lst_accuracy = []\n",
    "    \n",
    "    for epoch in tqdm_notebook(range(1, num_epochs+1), desc=\"Training\"):\n",
    "        start_time = time.time()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        lr = scheduler.get_lr()[0]\n",
    "        writer.add_scalar('learning_rate', lr, epoch)\n",
    "\n",
    "        model.train()\n",
    "        train_loss_total = 0.0\n",
    "        num_steps = 0\n",
    "    \n",
    "        for i, batch in enumerate(train_loader):\n",
    "            input_samples = batch[\"input\"]\n",
    "            input_labels = get_modality(batch)\n",
    "            \n",
    "            var_input = input_samples.cuda()\n",
    "            var_labels = torch.cuda.LongTensor(input_labels).cuda(non_blocking=True)\n",
    "\n",
    "            outputs = model(var_input)\n",
    "            \n",
    "            loss = criterion(outputs, var_labels)\n",
    "            train_loss_total += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            num_steps += 1\n",
    "            \n",
    "        train_loss_total_avg = train_loss_total / num_steps\n",
    "        lst_train_loss.append(train_loss_total_avg)\n",
    "        \n",
    "        #tqdm.write(f\"Epoch {epoch} training loss: {train_loss_total_avg:.4f}.\")\n",
    "        print(f\"Epoch {epoch} training loss: {train_loss_total_avg:.4f}.\")\n",
    "        \n",
    "        \n",
    "        # Validation loop -----------------------------------------------------\n",
    "        model.eval()\n",
    "        val_loss_total = 0.0\n",
    "        num_steps = 0\n",
    "        \n",
    "        val_accuracy = 0\n",
    "        num_samples = 0\n",
    "    \n",
    "        \n",
    "        for i, batch in enumerate(val_loader):\n",
    "            input_samples = batch[\"input\"]\n",
    "            input_labels = get_modality(batch)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                var_input = input_samples.cuda()\n",
    "                var_labels = torch.cuda.LongTensor(input_labels).cuda(non_blocking=True)\n",
    "\n",
    "                outputs = model(var_input)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                loss = criterion(outputs, var_labels)\n",
    "                val_loss_total += loss.item()\n",
    "                \n",
    "                val_accuracy += int((var_labels == preds).sum())\n",
    "                \n",
    "            num_steps += 1\n",
    "            num_samples += context['batch_size']\n",
    "            \n",
    "        val_loss_total_avg = val_loss_total / num_steps\n",
    "        lst_val_loss.append(val_loss_total_avg)\n",
    "        \n",
    "        #tqdm.write(f\"Epoch {epoch} validation loss: {val_loss_total_avg:.4f}.\")\n",
    "        print(f\"Epoch {epoch} validation loss: {val_loss_total_avg:.4f}.\")\n",
    "        \n",
    "        val_accuracy_avg = 100 * val_accuracy / num_samples\n",
    "        lst_accuracy.append(val_accuracy_avg)\n",
    "        \n",
    "        #tqdm.write(f\"Epoch {epoch} accuracy : {val_accuracy_avg:.4f}.\")\n",
    "        print(f\"Epoch {epoch} accuracy : {val_accuracy_avg:.4f} %.\")\n",
    "        \n",
    "        #add metrics for tensorboard\n",
    "        writer.add_scalars('accuracy', val_accuracy_avg, epoch)\n",
    "        writer.add_scalars('losses', {\n",
    "            'train_loss': train_loss_total_avg,\n",
    "            'val_loss': val_loss_total_avg,\n",
    "        }, epoch)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        #tqdm.write(\"Epoch {} took {:.2f} seconds.\".format(epoch, total_time))\n",
    "        print(\"Epoch {} took {:.2f} seconds.\".format(epoch, total_time))\n",
    "        \n",
    "        \n",
    "        if val_loss_total_avg < best_validation_loss:\n",
    "            best_validation_loss = val_loss_total_avg\n",
    "            torch.save(model, \"./\"+context[\"log_directory\"]+\"/best_model.pt\")\n",
    "\n",
    "        \n",
    "    # save final model\n",
    "    torch.save(model, \"./\"+context[\"log_directory\"]+\"/final_model.pt\")\n",
    "    \n",
    "    # display and save the metrics\n",
    "    parameters = \"CrossEntropyLoss, batchsize=\" + str(context['batch_size'])\n",
    "    parameters += \", initial_lr=\" + str(context['initial_lr'])\n",
    "    parameters += \", dropout=\" + str(context['dropout_rate'])\n",
    "    \n",
    "    \n",
    "    plt.subplot(2,1,1)\n",
    "    plt.title(parameters)\n",
    "    plt.plot(lst_train_loss, color='red', label='Training')\n",
    "    plt.plot(lst_val_loss, color='blue', label='Validation')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(lst_accuracy)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    \n",
    "    plt.savefig(parameters+'.png')\n",
    "    plt.show()    \n",
    "    return\n",
    "\n",
    "\n",
    "def run_main(command):\n",
    "    with open('config.json') as fhandle:\n",
    "        context = json.load(fhandle)\n",
    "\n",
    "    #command = context[\"command\"]\n",
    "\n",
    "    if command == 'train':\n",
    "        cmd_train(context)\n",
    "        #shutil.copyfile(sys.argv[1], \"./\"+context[\"log_directory\"]+\"/config_file.json\")\n",
    "    elif command == 'test':\n",
    "        cmd_test(context)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a16ce504454144beb883851e467fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading training set', max=18, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-605e57d8d36f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-cb10cc77f401>\u001b[0m in \u001b[0;36mrun_main\u001b[0;34m(command)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mcmd_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;31m#shutil.copyfile(sys.argv[1], \"./\"+context[\"log_directory\"]+\"/config_file.json\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-cb10cc77f401>\u001b[0m in \u001b[0;36mcmd_train\u001b[0;34m(context)\u001b[0m\n\u001b[1;32m    109\u001b[0m         ds_train = BidsDataset(bids_ds,\n\u001b[1;32m    110\u001b[0m                                \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                                slice_filter_fn=SliceFilter())\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mtrain_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-97debbe02628>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root_dir, slice_axis, cache, transform, slice_filter_fn, canonical, labeled)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         super().__init__(self.filename_pairs, slice_axis, cache,\n\u001b[0;32m---> 89\u001b[0;31m                          transform, slice_filter_fn, canonical)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/medicaltorch/datasets.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename_pairs, slice_axis, cache, transform, slice_filter_fn, canonical)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_filenames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_filenames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/medicaltorch/datasets.py\u001b[0m in \u001b[0;36m_prepare_indexes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_filter_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                     slice_pair = segpair.get_pair_slice(segpair_slice,\n\u001b[0;32m--> 230\u001b[0;31m                                                         self.slice_axis)\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mfilter_fn_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_filter_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-97debbe02628>\u001b[0m in \u001b[0;36mget_pair_slice\u001b[0;34m(self, slice_index, slice_axis)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_pair_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mdreturn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pair_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"slice_index\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mdreturn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_metadata\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bids_metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/medicaltorch/datasets.py\u001b[0m in \u001b[0;36mget_pair_slice\u001b[0;34m(self, slice_index, slice_axis)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0minput_dataobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_dataobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pair_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;31m# use dataobj to avoid caching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/medicaltorch/datasets.py\u001b[0m in \u001b[0;36mget_pair_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m         numpy array.\"\"\"\n\u001b[1;32m    117\u001b[0m         \u001b[0mcache_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'fill'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'unchanged'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# Handle unlabeled data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/nibabel/dataobj_images.py\u001b[0m in \u001b[0;36mget_fdata\u001b[0;34m(self, caching, dtype)\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fdata_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fdata_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcaching\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fill'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fdata_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m     \"\"\"\n\u001b[0;32m--> 591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/nibabel/arrayproxy.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;31m# Read array and scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unscaled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_read_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/nibabel/arrayproxy.py\u001b[0m in \u001b[0;36mget_unscaled\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    349\u001b[0m                                        \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                                        \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                                        mmap=self._mmap)\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/nibabel/volumeutils.py\u001b[0m in \u001b[0;36marray_from_file\u001b[0;34m(shape, in_dtype, infile, offset, order, mmap)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'readinto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mdata_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mn_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0mneeds_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    483\u001b[0m                                \"end-of-stream marker was reached\")\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_read_data\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0muncompress\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muncompress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0muncompress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36m_add_read_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_read_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_crc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrc32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_crc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_main('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def plot_metrics(metrics, acc, classes,\n",
    "                title=\"Validation metrics\",\n",
    "                cmap=None):\n",
    "    \n",
    "    colors = [(1,1,1), (1,1,1), (1,1,1)]\n",
    "    cm = LinearSegmentedColormap.from_list(\"white\",colors,N=1)\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    im = ax.imshow(metrics, interpolation=None, cmap=cm)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(metrics.shape[1]),\n",
    "           yticks=np.arange(metrics.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=[\"Recall\", \"Precision\"],\n",
    "           title=\"Accuracy over slices = \"+str(int(10000*acc)/100)+\"%\"\n",
    ")\n",
    "\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f'\n",
    "    for i in range(metrics.shape[0]):\n",
    "        for j in range(metrics.shape[1]):\n",
    "            ax.text(j, i, format(metrics[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"black\")\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a slice by slice accuracy measurement on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmd_test(context):\n",
    "\n",
    "    # Set the GPU\n",
    "    gpu_number = int(0)\n",
    "    torch.cuda.set_device(gpu_number)\n",
    "\n",
    "    # These are the validation/testing transformations\n",
    "    val_transform = transforms.Compose([\n",
    "        mt_transforms.CenterCrop2D((128, 128)),\n",
    "        mt_transforms.ToTensor(),\n",
    "        mt_transforms.NormalizeInstance(),\n",
    "    ])\n",
    "\n",
    "    test_datasets = []\n",
    "    for bids_ds in tqdm_notebook(context[\"bids_path_test\"], desc=\"Loading test set\"):\n",
    "        ds_test = BidsDataset(bids_ds,\n",
    "                                     transform=val_transform,\n",
    "                                     slice_filter_fn=SliceFilter())\n",
    "        test_datasets.append(ds_test)\n",
    "\n",
    "\n",
    "    ds_test = ConcatDataset(test_datasets)\n",
    "    print(f\"Loaded {len(ds_test)} axial slices for the test set.\")\n",
    "    test_loader = DataLoader(ds_test, batch_size=context[\"batch_size\"],\n",
    "                             shuffle=True, pin_memory=True,\n",
    "                             collate_fn=mt_datasets.mt_collate,\n",
    "                             num_workers=1)\n",
    "\n",
    "    model = torch.load(\"./\"+context[\"log_directory\"]+\"/best_model.pt\", map_location=\"cuda:0\")\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    #setting the lists for confusion matrix\n",
    "    true_labels = []\n",
    "    guessed_labels = []\n",
    "\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        input_samples = batch[\"input\"]\n",
    "        input_labels = get_modality(batch)\n",
    "        \n",
    "        true_labels += input_labels\n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_input = input_samples.cuda()\n",
    "            test_labels = torch.cuda.LongTensor(input_labels).cuda(non_blocking=True)\n",
    "\n",
    "            outputs = model(test_input)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            lst_labels = [int(x) for x in preds]\n",
    "            guessed_labels += lst_labels\n",
    "            \n",
    "    accuracy = accuracy_score(true_labels, guessed_labels)\n",
    "    recall = recall_score(true_labels, guessed_labels, average=None)\n",
    "    precision = precision_score(true_labels, guessed_labels, average=None)\n",
    "    \n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    class_names = [\"MToff_MTS\", \"MTon_MTS\", \"T1w_MTS\", \"T1w\", \"T2star\", \"T2w\"]\n",
    "    # Plot normalized confusion matrix\n",
    "    plot_confusion_matrix(true_labels, guessed_labels, classes=class_names, normalize=True,\n",
    "                          title='Normalized confusion matrix')\n",
    "    plot_metrics(np.array([recall, precision]), accuracy, class_names)\n",
    "    print(f\"Accuracy over test slices : {accuracy}\")\n",
    "    print(f\"Recall over test slices : {recall}\")\n",
    "    print(f\"Precision over test slices : {precision}\")\n",
    "\n",
    "    plt.savefig(\"test_accuracy.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97952ebd034c482794556a70a2167447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading test set', max=4, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2036 axial slices for the test set.\n",
      "Accuracy over test slices : 0.9356581532416502\n",
      "Recall over test slices : [0.98 0.9  0.92 0.85 0.97 1.  ]\n",
      "Precision over test slices : [0.95 0.93 0.87 0.95 0.93 0.99]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_main(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we want to add another tool to visualize accuracy for whole acquisitions and make sure that accuracy remains high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/GRAMES.POLYMTL.CA/p112175/anaconda3/envs/py36/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/GRAMES.POLYMTL.CA/p112175/anaconda3/envs/py36/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/GRAMES.POLYMTL.CA/p112175/anaconda3/envs/py36/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/GRAMES.POLYMTL.CA/p112175/anaconda3/envs/py36/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/GRAMES.POLYMTL.CA/p112175/anaconda3/envs/py36/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Softmax' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "from sklearn.preprocessing import normalize\n",
    "from statistics import mode\n",
    "\n",
    "def transform(input_slices):\n",
    "    slices = []\n",
    "    for i in range(input_slices.shape[2]):\n",
    "        w,h = input_slices.shape[0], input_slices.shape[1]\n",
    "        c1,c2 = w//2 - 64, w//2 + 64\n",
    "        c3,c4 = h//2 - 64, h//2 + 64\n",
    "        \n",
    "        normalized_slice = normalize(input_slices[c1:c2,c3:c4,i])\n",
    "        transposed_slice = np.transpose(normalized_slice)\n",
    "        slices.append(np.expand_dims(transposed_slice, axis=0))\n",
    "    slices = torch.FloatTensor(slices)\n",
    "    return(slices)\n",
    "    \n",
    "def acquisition_predict(path, model=None):\n",
    "       \n",
    "    slices = transform(nib.load(path).get_data())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        slices = slices.cuda()\n",
    "\n",
    "        outputs = model(slices)   \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        preds = preds.tolist()\n",
    "\n",
    "        print(preds)\n",
    "        \n",
    "    modality = mode(preds)\n",
    "    return(modality)\n",
    "\n",
    "model = torch.load(\"./log_baseline/best_model.pt\", map_location=\"cuda:0\")\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "acquisition_predict(\"../duke/projects/ivado-medical-imaging/spineGeneric_201904271322/result/juntendo-750w_spineGeneric/sub-02/anat/sub-02_T1w.nii.gz\", model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical accuracy evaluation\n",
    "\n",
    "Since we only measured the accuracy over each slice we have to measure the accuracy for a whole acquisition comprising several (at leat 15) tranches. If we consider the label that appears the most among the acquisition we obtain the estimated label for the acquisition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tirage(accuracy):\n",
    "    x = np.random.rand()\n",
    "    if x <= accuracy:\n",
    "        return([0,0,0,0,0,1])\n",
    "    else:\n",
    "        i = np.random.randint(4)\n",
    "        l = [0 for i in range(6)]\n",
    "        l[i] = 1\n",
    "        return(l)\n",
    "    \n",
    "def montecarlo(n):\n",
    "    accuracy = 0\n",
    "    for i in range(n):\n",
    "        # we average over 15 slices\n",
    "        labels = [0 for i in range(6)]\n",
    "        for j in range(15):\n",
    "            t = tirage()\n",
    "            labels = [x+y for x,y in zip(labels, t)]\n",
    "        label = labels.index(max(labels))\n",
    "        if label == 5:\n",
    "            accuracy += 1\n",
    "    return(100 * accuracy/n)\n",
    "            \n",
    "montecarlo(10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we manage to obtain a promising 99.988% accuracy for each acquisition, which is enough for a reliable release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config_small.json') as fhandle:\n",
    "        context = json.load(fhandle)\n",
    "\n",
    "# Set the GPU\n",
    "gpu_number = int(0)\n",
    "torch.cuda.set_device(gpu_number)\n",
    "\n",
    "# These are the validation/testing transformations\n",
    "val_transform = transforms.Compose([\n",
    "    mt_transforms.CenterCrop2D((128, 128)),\n",
    "    mt_transforms.ToTensor(),\n",
    "    mt_transforms.NormalizeInstance(),\n",
    "])\n",
    "\n",
    "test_datasets = []\n",
    "for bids_ds in tqdm_notebook(context[\"bids_path_test\"], desc=\"Loading test set\"):\n",
    "    ds_test = BidsDataset(bids_ds,\n",
    "                                 transform=val_transform,\n",
    "                                 slice_filter_fn=SliceFilter())\n",
    "    test_datasets.append(ds_test)\n",
    "\n",
    "\n",
    "ds_test = ConcatDataset(test_datasets)\n",
    "print(f\"Loaded {len(ds_test)} axial slices for the test set.\")\n",
    "test_loader = DataLoader(ds_test, batch_size=context[\"batch_size\"],\n",
    "                         shuffle=False, pin_memory=True,\n",
    "                         collate_fn=mt_datasets.mt_collate,\n",
    "                         num_workers=1)\n",
    "\n",
    "print(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./\"+context[\"log_directory\"]+\"/best_model.pt\", map_location=\"cuda:0\")\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "a = torch.rand(3,1,128,128)\n",
    "a = a.cuda()\n",
    "\n",
    "model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ivado",
   "language": "python",
   "name": "ivado"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
