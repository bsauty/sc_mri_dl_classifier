{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS Loader\n",
    "\n",
    "\n",
    "We use the data in `SpineGeneric`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bids_neuropoly import bids\n",
    "from medicaltorch import datasets as mt_datasets\n",
    "from medicaltorch import transforms as mt_transforms\n",
    "\n",
    "\n",
    "class BIDSSegPair2D(mt_datasets.SegmentationPair2D):\n",
    "    def __init__(self, input_filename, gt_filename, metadata):\n",
    "        super().__init__(input_filename, gt_filename)\n",
    "        self.metadata = metadata\n",
    "        self.metadata[\"input_filename\"] = input_filename\n",
    "        self.metadata[\"gt_filename\"] = gt_filename\n",
    "\n",
    "    def get_pair_slice(self, slice_index, slice_axis=2):\n",
    "        dreturn = super().get_pair_slice(slice_index, slice_axis)\n",
    "        self.metadata[\"slice_index\"] = slice_index\n",
    "        dreturn[\"input_metadata\"][\"bids_metadata\"] = self.metadata\n",
    "        return dreturn\n",
    "\n",
    "\n",
    "class MRI2DBidsSegDataset(mt_datasets.MRI2DSegmentationDataset):\n",
    "    def _load_filenames(self):\n",
    "        for input_filename, gt_filename, bids_metadata in self.filename_pairs:\n",
    "            segpair = BIDSSegPair2D(input_filename, gt_filename,\n",
    "                                    bids_metadata)\n",
    "            self.handlers.append(segpair)\n",
    "\n",
    "\n",
    "class BidsDataset(MRI2DBidsSegDataset):\n",
    "    def __init__(self, root_dir, slice_axis=2, cache=True,\n",
    "                 transform=None, slice_filter_fn=None,\n",
    "                 canonical=False, labeled=True):\n",
    "        self.bids_ds = bids.BIDS(root_dir)\n",
    "        self.filename_pairs = []\n",
    "\n",
    "        for subject in self.bids_ds.get_subjects():\n",
    "\n",
    "            derivatives = subject.get_derivatives(\"labels\")\n",
    "            cord_label_filename = None\n",
    "\n",
    "            for deriv in derivatives:\n",
    "                if deriv.endswith(\"seg-manual.nii.gz\"):\n",
    "                    cord_label_filename = deriv\n",
    "\n",
    "            if cord_label_filename is None:\n",
    "                continue\n",
    "\n",
    "            metadata = subject.metadata()\n",
    "            self.filename_pairs.append((subject.record.absolute_path,\n",
    "                                        cord_label_filename, metadata))\n",
    "            \n",
    "        super().__init__(self.filename_pairs, slice_axis, cache,\n",
    "                         transform, slice_filter_fn, canonical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Here we define the architecture of the network in a PyTorch Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "\n",
    "class DownConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, bn_momentum=0.1):\n",
    "        super(DownConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_ch, out_channels=out_ch, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_bn = nn.BatchNorm2d(out_ch, momentum=bn_momentum)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x))\n",
    "        x = self.conv_bn(x)\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, drop_rate=0.4, bn_momentum=0.1):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv1 = DownConv(1, 32, bn_momentum)\n",
    "        self.mp1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv2 = DownConv(32, 32, bn_momentum)\n",
    "        self.mp2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv3 = DownConv(32, 64, bn_momentum)\n",
    "        self.mp3 = nn.MaxPool2d(2)       \n",
    "        \n",
    "        self.flat = Flatten()\n",
    "        self.dense1 = nn.Linear(16384, 256)\n",
    "        self.drop = nn.Dropout2d(drop_rate)\n",
    "        self.dense2 = nn.Linear(256, 6)\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.mp1(x1)\n",
    "        \n",
    "        x3 = self.conv2(x2)\n",
    "        x4 = self.mp2(x3)\n",
    "        \n",
    "        x5 = self.conv3(x4)\n",
    "        x6 = self.mp3(x5)\n",
    "        \n",
    "        x7 = self.flat(x6)\n",
    "        x8 = self.dense1(x7)\n",
    "        x9 = self.drop(x8)\n",
    "        x10 = self.dense2(x9)\n",
    "        x11 = self.soft(x10)\n",
    "\n",
    "        return(x11)\n",
    "\n",
    "#torch tensors are of the format (batch_size, n_channels, shape_of_image)\n",
    "a = torch.rand(18,1,128,128)\n",
    "test = Classifier().forward(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import time\n",
    "import shutil\n",
    "import sys\n",
    "import pickle\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "def get_modality(batch):\n",
    "    labels = []\n",
    "    for acq in batch['input_metadata']:\n",
    "        path = acq.__getitem__('bids_metadata')['input_filename']\n",
    "        name = os.path.basename(path)\n",
    "        if \"acq-MToff_MTS\" in name :\n",
    "            labels.append(0)\n",
    "            continue\n",
    "        if \"acq-MTon_MTS\" in name :\n",
    "            labels.append(1)\n",
    "            continue\n",
    "        if \"acq-T1w_MTS\" in name :\n",
    "            labels.append(2)\n",
    "            continue\n",
    "        if \"T1w\" in name :\n",
    "            labels.append(3)\n",
    "            continue\n",
    "        if \"T2star\" in name :\n",
    "            labels.append(4)\n",
    "            continue\n",
    "        if \"T2w\" in name :\n",
    "            labels.append(5) \n",
    "            continue\n",
    "    return labels\n",
    "\n",
    "def OneHotEncode(labels):\n",
    "    ohe_labels = []\n",
    "    for label in labels :\n",
    "        ohe = [0 for i in range(6)]\n",
    "        ohe[label] = 1 \n",
    "        ohe_labels.append(ohe)\n",
    "    return torch.FloatTensor(ohe_labels)\n",
    "\n",
    "\n",
    "def cmd_train(context):\n",
    "    \"\"\"Main command do train the network.\n",
    "    :param context: this is a dictionary with all data from the\n",
    "                    configuration file:\n",
    "                        - 'command': run the specified command (e.g. train, test)\n",
    "                        - 'gpu': ID of the used GPU\n",
    "                        - 'bids_path_train': list of relative paths of the BIDS folders of each training center\n",
    "                        - 'bids_path_validation': list of relative paths of the BIDS folders of each validation center\n",
    "                        - 'bids_path_test': list of relative paths of the BIDS folders of each test center\n",
    "                        - 'batch_size'\n",
    "                        - 'dropout_rate'\n",
    "                        - 'batch_norm_momentum'\n",
    "                        - 'num_epochs'\n",
    "                        - 'initial_lr': initial learning rate\n",
    "                        - 'log_directory': folder name where log files are saved\n",
    "                        - 'debugging': allows extended verbosity and intermediate outputs\n",
    "    \"\"\"\n",
    "    # Set the GPU\n",
    "    gpu_number = int(0)\n",
    "    torch.cuda.set_device(gpu_number)\n",
    "\n",
    "    # These are the training transformations\n",
    "    train_transform = transforms.Compose([\n",
    "        mt_transforms.CenterCrop2D((128, 128)),\n",
    "        mt_transforms.ElasticTransform(alpha_range=(28.0, 30.0),\n",
    "                                       sigma_range=(3.5, 4.0),\n",
    "                                       p=0.3),\n",
    "        mt_transforms.RandomAffine(degrees=4.6,\n",
    "                                   scale=(0.98, 1.02),\n",
    "                                   translate=(0.03, 0.03)),\n",
    "        mt_transforms.RandomTensorChannelShift((-0.10, 0.10)),\n",
    "        mt_transforms.ToTensor(),\n",
    "        mt_transforms.NormalizeInstance(),\n",
    "    ])\n",
    "\n",
    "    # These are the validation/testing transformations\n",
    "    val_transform = transforms.Compose([\n",
    "        mt_transforms.CenterCrop2D((128, 128)),\n",
    "        mt_transforms.ToTensor(),\n",
    "        mt_transforms.NormalizeInstance(),\n",
    "    ])\n",
    "\n",
    "    # This code will iterate over the folders and load the data, filtering\n",
    "    # the slices without labels and then concatenating all the datasets together\n",
    "    train_datasets = []\n",
    "    for bids_ds in tqdm_notebook(context[\"bids_path_train\"], desc=\"Loading training set\"):\n",
    "        ds_train = BidsDataset(bids_ds,\n",
    "                               transform=train_transform)\n",
    "        train_datasets.append(ds_train)\n",
    "\n",
    "    ds_train = ConcatDataset(train_datasets)\n",
    "    print(f\"Loaded {len(ds_train)} axial slices for the training set.\")\n",
    "    train_loader = DataLoader(ds_train, batch_size=context[\"batch_size\"],\n",
    "                              shuffle=True, pin_memory=True,\n",
    "                              collate_fn=mt_datasets.mt_collate,\n",
    "                              num_workers=1)\n",
    "\n",
    "    # Validation dataset ------------------------------------------------------\n",
    "    validation_datasets = []\n",
    "    for bids_ds in tqdm_notebook(context[\"bids_path_validation\"], desc=\"Loading validation set\"):\n",
    "        ds_val = BidsDataset(bids_ds,\n",
    "                             transform=val_transform)\n",
    "        validation_datasets.append(ds_val)\n",
    "\n",
    "    ds_val = ConcatDataset(validation_datasets)\n",
    "    print(f\"Loaded {len(ds_val)} axial slices for the validation set.\")\n",
    "    val_loader = DataLoader(ds_val, batch_size=context[\"batch_size\"],\n",
    "                            shuffle=True, pin_memory=True,\n",
    "                            collate_fn=mt_datasets.mt_collate,\n",
    "                            num_workers=1)\n",
    "\n",
    "    model = Classifier(drop_rate=context[\"dropout_rate\"],\n",
    "                       bn_momentum=context[\"batch_norm_momentum\"])\n",
    "    model.cuda()\n",
    "\n",
    "    num_epochs = context[\"num_epochs\"]\n",
    "    initial_lr = context[\"initial_lr\"]\n",
    "\n",
    "    # Using Adam with cosine annealing learning rate\n",
    "    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)\n",
    "\n",
    "    # Write the metrics, images, etc to TensorBoard format\n",
    "    writer = SummaryWriter(log_dir=context[\"log_directory\"])\n",
    "\n",
    "    # Training loop -----------------------------------------------------------\n",
    "    best_validation_loss = float(\"inf\")\n",
    "    for epoch in tqdm_notebook(range(1, num_epochs+1), desc=\"Training\"):\n",
    "        start_time = time.time()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        lr = scheduler.get_lr()[0]\n",
    "        writer.add_scalar('learning_rate', lr, epoch)\n",
    "\n",
    "        model.train()\n",
    "        train_loss_total = 0.0\n",
    "        num_steps = 0\n",
    "        \n",
    "        for i, batch in enumerate(train_loader):\n",
    "            input_samples = batch[\"input\"]\n",
    "            input_labels = get_modality(batch)\n",
    "            \n",
    "            var_input = input_samples.cuda()\n",
    "            var_labels = OneHotEncode(input_labels).cuda()\n",
    "\n",
    "            preds = model(var_input)\n",
    "\n",
    "            CE_loss = nn.BCEWithLogitsLoss()\n",
    "            loss = CE_loss(preds, var_labels)\n",
    "            train_loss_total += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            num_steps += 1\n",
    "\n",
    "        train_loss_total_avg = train_loss_total / num_steps\n",
    "\n",
    "        #tqdm.write(f\"Epoch {epoch} training loss: {train_loss_total_avg:.4f}.\")\n",
    "        print(f\"Epoch {epoch} training loss: {train_loss_total_avg:.4f}.\")\n",
    "        \n",
    "        # Validation loop -----------------------------------------------------\n",
    "        model.eval()\n",
    "        val_loss_total = 0.0\n",
    "        num_steps = 0\n",
    "\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            input_samples = batch[\"input\"]\n",
    "            input_labels = get_modality(batch)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                var_input = input_samples.cuda()\n",
    "                var_labels = OneHotEncode(input_labels).cuda()\n",
    "\n",
    "                preds = model(var_input)\n",
    "\n",
    "                CE_loss = nn.BCEWithLogitsLoss()\n",
    "                loss = CE_loss(preds, var_labels)\n",
    "                val_loss_total += loss.item()\n",
    "\n",
    "            num_steps += 1\n",
    "\n",
    "        val_loss_total_avg = val_loss_total / num_steps\n",
    "\n",
    "        #tqdm.write(f\"Epoch {epoch} validation loss: {val_loss_total_avg:.4f}.\")\n",
    "        print(f\"Epoch {epoch} validation loss: {val_loss_total_avg:.4f}.\")\n",
    "        \n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        #tqdm.write(\"Epoch {} took {:.2f} seconds.\".format(epoch, total_time))\n",
    "        print(\"Epoch {} took {:.2f} seconds.\".format(epoch, total_time))\n",
    "        \n",
    "        if val_loss_total_avg < best_validation_loss:\n",
    "            best_validation_loss = val_loss_total_avg\n",
    "            torch.save(model, \"./\"+context[\"log_directory\"]+\"/best_model.pt\")\n",
    "\n",
    "    # save final model\n",
    "    torch.save(model, \"./\"+context[\"log_directory\"]+\"/final_model.pt\")\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def run_main(command):\n",
    "    with open('config_small.json') as fhandle:\n",
    "        context = json.load(fhandle)\n",
    "\n",
    "    #command = context[\"command\"]\n",
    "\n",
    "    if command == 'train':\n",
    "        cmd_train(context)\n",
    "        shutil.copyfile(sys.argv[1], \"./\"+context[\"log_directory\"]+\"/config_file.json\")\n",
    "    elif command == 'test':\n",
    "        cmd_test(context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6da88d173134fc598e6b657d3067f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading training set', max=9, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4810 axial slices for the training set.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e36e18d66294fe69d11d84c43b69144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading validation set', max=2, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1656 axial slices for the validation set.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e875fcdf0e48dc827db501c188983e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', style=ProgressStyle(description_width='initial')),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 training loss: 0.6989.\n",
      "Epoch 1 validation loss: 0.7038.\n",
      "Epoch 1 took 249.40 seconds.\n",
      "Epoch 2 training loss: 0.7009.\n",
      "Epoch 2 validation loss: 0.7135.\n",
      "Epoch 2 took 265.65 seconds.\n",
      "Epoch 3 training loss: 0.7152.\n",
      "Epoch 3 validation loss: 0.7318.\n",
      "Epoch 3 took 252.84 seconds.\n",
      "Epoch 4 training loss: 0.7040.\n",
      "Epoch 4 validation loss: 0.7057.\n",
      "Epoch 4 took 275.28 seconds.\n",
      "Epoch 5 training loss: 0.6908.\n",
      "Epoch 5 validation loss: 0.6872.\n",
      "Epoch 5 took 233.05 seconds.\n",
      "Epoch 6 training loss: 0.6772.\n",
      "Epoch 6 validation loss: 0.6884.\n",
      "Epoch 6 took 172.90 seconds.\n",
      "Epoch 7 training loss: 0.6847.\n",
      "Epoch 7 validation loss: 0.7035.\n",
      "Epoch 7 took 176.24 seconds.\n",
      "Epoch 8 training loss: 0.6767.\n",
      "Epoch 8 validation loss: 0.6807.\n",
      "Epoch 8 took 173.23 seconds.\n",
      "Epoch 9 training loss: 0.6771.\n",
      "Epoch 9 validation loss: 0.6877.\n",
      "Epoch 9 took 173.74 seconds.\n",
      "Epoch 10 training loss: 0.6785.\n",
      "Epoch 10 validation loss: 0.6802.\n",
      "Epoch 10 took 170.21 seconds.\n",
      "Epoch 11 training loss: 0.6760.\n",
      "Epoch 11 validation loss: 0.6875.\n",
      "Epoch 11 took 180.18 seconds.\n",
      "Epoch 12 training loss: 0.6766.\n",
      "Epoch 12 validation loss: 0.6851.\n",
      "Epoch 12 took 174.87 seconds.\n",
      "Epoch 13 training loss: 0.6752.\n",
      "Epoch 13 validation loss: 0.6923.\n",
      "Epoch 13 took 176.78 seconds.\n",
      "Epoch 14 training loss: 0.6735.\n",
      "Epoch 14 validation loss: 0.6825.\n",
      "Epoch 14 took 175.21 seconds.\n",
      "Epoch 15 training loss: 0.6736.\n",
      "Epoch 15 validation loss: 0.6764.\n",
      "Epoch 15 took 175.80 seconds.\n",
      "Epoch 16 training loss: 0.6715.\n",
      "Epoch 16 validation loss: 0.6811.\n",
      "Epoch 16 took 170.58 seconds.\n",
      "Epoch 17 training loss: 0.6745.\n",
      "Epoch 17 validation loss: 0.6754.\n",
      "Epoch 17 took 174.74 seconds.\n",
      "Epoch 18 training loss: 0.6778.\n",
      "Epoch 18 validation loss: 0.6804.\n",
      "Epoch 18 took 178.43 seconds.\n",
      "Epoch 19 training loss: 0.6766.\n",
      "Epoch 19 validation loss: 0.6812.\n",
      "Epoch 19 took 224.48 seconds.\n",
      "Epoch 20 training loss: 0.6747.\n"
     ]
    }
   ],
   "source": [
    "run_main('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_main('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config_small.json') as fhandle:\n",
    "    context = json.load(fhandle)\n",
    "\n",
    "command = context[\"command\"]\n",
    "\n",
    "if command == 'train':\n",
    "    cmd_train(context)\n",
    "    shutil.copyfile(sys.argv[1], \"./\"+context[\"log_directory\"]+\"/config_file.json\")\n",
    "elif command == 'test':\n",
    "    cmd_test(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds = torch.rand(18,6)\n",
    "preds_norm = nn.Softmax()\n",
    "labels = [4, 5, 1, 3, 2, 5, 2, 5, 0, 3, 1, 0, 4, 0, 3, 0, 5, 3]\n",
    "var_labels = []\n",
    "for l in labels :\n",
    "    a = [0 for i in range(6)]\n",
    "    a[l] = 1 \n",
    "    var_labels.append(a)\n",
    "var_labels = torch.FloatTensor(var_labels)\n",
    "\n",
    "\n",
    "\n",
    "CS_loss = nn.BCELoss()\n",
    "loss = CS_loss(var_labels, preds)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ivado",
   "language": "python",
   "name": "ivado"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
